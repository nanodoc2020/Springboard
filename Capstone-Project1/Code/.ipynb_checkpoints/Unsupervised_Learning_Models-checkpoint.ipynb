{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "This notebook contains code and analysis for a K-Means clustering algorithm and a small neural network both trained on the seeds dataset. All data has been previously cleaned and prepared in separate notebooks. Performance will be compared, along with that of models from the Logistic_Regression notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>asymmetry_coefficient</th>\n",
       "      <th>groove_length</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length  width  asymmetry_coefficient  \\\n",
       "0  15.26      14.84       0.8710   5.763  3.312                  2.221   \n",
       "1  14.88      14.57       0.8811   5.554  3.333                  1.018   \n",
       "2  14.29      14.09       0.9050   5.291  3.337                  2.699   \n",
       "3  13.84      13.94       0.8955   5.324  3.379                  2.259   \n",
       "4  16.14      14.99       0.9034   5.658  3.562                  1.355   \n",
       "\n",
       "   groove_length  class  \n",
       "0          5.220    1.0  \n",
       "1          4.956    1.0  \n",
       "2          4.825    1.0  \n",
       "3          4.805    1.0  \n",
       "4          5.175    1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a dataframe\n",
    "seeds = pd.read_csv('seeds.csv')\n",
    "\n",
    "# Create versions of X and y with dropped superfluous columns\n",
    "X = seeds.drop(['compactness', 'class'], axis=1)\n",
    "X2 = seeds.drop(['compactness', 'perimeter', 'class'], axis=1)\n",
    "X3 = seeds.drop(['compactness', 'area', 'class'], axis=1)\n",
    "\n",
    "y = seeds.loc[:,'class']\n",
    "\n",
    "# Display the seeds dataframe\n",
    "seeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=.2, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifiers\n",
    "kmn = KMeans(max_iter=5000)\n",
    "kmn2 = KMeans(max_iter=5000)\n",
    "kmn3 = KMeans(max_iter=5000)\n",
    "\n",
    "# Fit the classifiers \n",
    "kmn.fit(X_train)\n",
    "kmn2.fit(X2_train)\n",
    "kmn3.fit(X3_train)\n",
    "\n",
    "# Get cluster centers and predicted labels\n",
    "cluster_centers=kmn.cluster_centers_\n",
    "cluster_centers2=kmn2.cluster_centers_\n",
    "cluster_centers3=kmn3.cluster_centers_\n",
    "\n",
    "labels=kmn.labels_\n",
    "labels2=kmn2.labels_\n",
    "labels3=kmn3.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percent correct on training set: 0.0 %\n",
      "\n",
      "Percent correct on training set 2: 9.524 %\n",
      "\n",
      "Percent correct on training set 3: 14.881 %\n"
     ]
    }
   ],
   "source": [
    "# Check for accuracy directly\n",
    "outcome = labels==y_train\n",
    "outcome2 = labels2==y2_train\n",
    "outcome3 = labels3==y3_train\n",
    "\n",
    "print('\\nPercent correct on training set:',round(sum(outcome)/len(outcome)*100, 3),'%')\n",
    "print('\\nPercent correct on training set 2:',round(sum(outcome2)/len(outcome2)*100, 3),'%')\n",
    "print('\\nPercent correct on training set 3:',round(sum(outcome3)/len(outcome3)*100, 3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percent correct on test set: 0.0 %\n",
      "\n",
      "Percent correct on test set 2: 9.524 %\n",
      "\n",
      "Percent correct on test set 3: 2.381 %\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "prediction = kmn.predict(X_test)\n",
    "prediction2 = kmn2.predict(X2_test)\n",
    "prediction3 = kmn3.predict(X3_test)\n",
    "\n",
    "# Check for accuracy directly\n",
    "outcome = prediction==y_test\n",
    "outcome2 = prediction2==y2_test\n",
    "outcome3 = prediction3==y3_test\n",
    "print('\\nPercent correct on test set:',round(sum(outcome)/len(outcome)*100, 3),'%')\n",
    "print('\\nPercent correct on test set 2:',round(sum(outcome2)/len(outcome2)*100, 3),'%')\n",
    "print('\\nPercent correct on test set 3:',round(sum(outcome3)/len(outcome3)*100, 3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-means classifier does not perform as well as logistic regression or even naive Bayes models. Even with highly correlated features removed, the model performs poorly. This is likely due to the limited data size paired with a train_test_split that may include the outliers in the test set. It would be very difficult to correctly classify seeds whose geometric profiles overlap. The supervised k-nearest-neighbors model provides better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters\n",
    "num_nodes = len(X_train.columns)*2\n",
    "num_epochs = 1000\n",
    "stop_pat = 25\n",
    "out_nodes = 4\n",
    "\n",
    "# Create the model\n",
    "nn = Sequential()\n",
    "nn2 = Sequential()\n",
    "nn3 = Sequential()\n",
    "\n",
    "# Specify the input dimension\n",
    "in_dim = len(X_train.columns)\n",
    "in2_dim = len(X2_train.columns)\n",
    "in3_dim = len(X3_train.columns)\n",
    "\n",
    "# Add layers to the models\n",
    "nn.add(Dense(num_nodes, activation='relu', input_dim=in_dim))\n",
    "nn.add(Dense(num_nodes, activation='relu'))\n",
    "nn.add(Dense(num_nodes, activation='relu'))\n",
    "\n",
    "nn2.add(Dense(num_nodes, activation='relu', input_dim=in2_dim))\n",
    "nn2.add(Dense(num_nodes, activation='relu'))\n",
    "nn2.add(Dense(num_nodes, activation='relu'))\n",
    "\n",
    "nn3.add(Dense(num_nodes, activation='relu', input_dim=in3_dim))\n",
    "nn3.add(Dense(num_nodes, activation='relu'))\n",
    "nn3.add(Dense(num_nodes, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "nn.add(Dense(out_nodes, activation='softmax'))\n",
    "nn2.add(Dense(out_nodes, activation='softmax'))\n",
    "nn3.add(Dense(out_nodes, activation='softmax'))\n",
    "\n",
    "# Compile the models\n",
    "nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "nn2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "nn3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=stop_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 42 samples\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 2.1685 - accuracy: 0.3333 - val_loss: 1.6921 - val_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 1.6318 - accuracy: 0.3333 - val_loss: 1.2869 - val_accuracy: 0.3333\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.2781 - accuracy: 0.3452 - val_loss: 1.0827 - val_accuracy: 0.5000\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0702 - accuracy: 0.5357 - val_loss: 0.9876 - val_accuracy: 0.5476\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 404us/step - loss: 0.9862 - accuracy: 0.5000 - val_loss: 0.9588 - val_accuracy: 0.5238\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 250us/step - loss: 0.9499 - accuracy: 0.5298 - val_loss: 0.9082 - val_accuracy: 0.6429\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 252us/step - loss: 0.9269 - accuracy: 0.5417 - val_loss: 0.9022 - val_accuracy: 0.6429\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9143 - accuracy: 0.6071 - val_loss: 0.9077 - val_accuracy: 0.5714\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9072 - accuracy: 0.5476 - val_loss: 0.8827 - val_accuracy: 0.6429\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.8934 - accuracy: 0.5714 - val_loss: 0.9076 - val_accuracy: 0.4762\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8940 - accuracy: 0.5417 - val_loss: 0.8891 - val_accuracy: 0.5952\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8726 - accuracy: 0.6429 - val_loss: 0.8513 - val_accuracy: 0.6905\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8649 - accuracy: 0.6548 - val_loss: 0.8334 - val_accuracy: 0.8095\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8625 - accuracy: 0.6607 - val_loss: 0.8434 - val_accuracy: 0.6190\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8532 - accuracy: 0.6190 - val_loss: 0.8202 - val_accuracy: 0.6905\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 357us/step - loss: 0.8384 - accuracy: 0.6488 - val_loss: 0.8216 - val_accuracy: 0.7857\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.7913 - accuracy: 0.71 - 0s 186us/step - loss: 0.8235 - accuracy: 0.7262 - val_loss: 0.8225 - val_accuracy: 0.6429\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.8154 - accuracy: 0.6845 - val_loss: 0.7911 - val_accuracy: 0.7619\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8077 - accuracy: 0.7083 - val_loss: 0.7771 - val_accuracy: 0.8333\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.8023 - accuracy: 0.7321 - val_loss: 0.7810 - val_accuracy: 0.8095\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7833 - accuracy: 0.7857 - val_loss: 0.7548 - val_accuracy: 0.7619\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 375us/step - loss: 0.7824 - accuracy: 0.6786 - val_loss: 0.7500 - val_accuracy: 0.7857\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 321us/step - loss: 0.7619 - accuracy: 0.7976 - val_loss: 0.7626 - val_accuracy: 0.5952\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.7651 - accuracy: 0.6548 - val_loss: 0.7536 - val_accuracy: 0.5952\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7513 - accuracy: 0.7321 - val_loss: 0.7206 - val_accuracy: 0.7143\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7492 - accuracy: 0.6548 - val_loss: 0.7309 - val_accuracy: 0.8571\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7308 - accuracy: 0.8512 - val_loss: 0.7208 - val_accuracy: 0.7619\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7243 - accuracy: 0.8393 - val_loss: 0.6963 - val_accuracy: 0.7857\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7089 - accuracy: 0.8690 - val_loss: 0.7009 - val_accuracy: 0.7143\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7074 - accuracy: 0.6905 - val_loss: 0.6986 - val_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6981 - accuracy: 0.8214 - val_loss: 0.6801 - val_accuracy: 0.8571\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6851 - accuracy: 0.8512 - val_loss: 0.6762 - val_accuracy: 0.8571\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 412us/step - loss: 0.6767 - accuracy: 0.8869 - val_loss: 0.6650 - val_accuracy: 0.8571\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 246us/step - loss: 0.6693 - accuracy: 0.8929 - val_loss: 0.6570 - val_accuracy: 0.7857\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.6637 - accuracy: 0.8571 - val_loss: 0.6541 - val_accuracy: 0.8095\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6626 - accuracy: 0.7917 - val_loss: 0.6283 - val_accuracy: 0.7619\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.6520 - accuracy: 0.8095 - val_loss: 0.6276 - val_accuracy: 0.8571\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.6334 - accuracy: 0.8988 - val_loss: 0.6138 - val_accuracy: 0.8571\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 474us/step - loss: 0.6410 - accuracy: 0.8690 - val_loss: 0.6034 - val_accuracy: 0.8333\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 292us/step - loss: 0.6232 - accuracy: 0.8750 - val_loss: 0.6321 - val_accuracy: 0.8571\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 261us/step - loss: 0.6258 - accuracy: 0.8631 - val_loss: 0.6273 - val_accuracy: 0.8810\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6081 - accuracy: 0.8869 - val_loss: 0.5906 - val_accuracy: 0.8095\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 558us/step - loss: 0.5988 - accuracy: 0.8631 - val_loss: 0.5849 - val_accuracy: 0.8333\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5967 - accuracy: 0.8810 - val_loss: 0.5861 - val_accuracy: 0.8095\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5846 - accuracy: 0.9048 - val_loss: 0.5671 - val_accuracy: 0.8095\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5799 - accuracy: 0.8869 - val_loss: 0.5715 - val_accuracy: 0.8333\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5731 - accuracy: 0.8631 - val_loss: 0.5636 - val_accuracy: 0.7857\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.5645 - accuracy: 0.8750 - val_loss: 0.5600 - val_accuracy: 0.8333\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 376us/step - loss: 0.5586 - accuracy: 0.8929 - val_loss: 0.5594 - val_accuracy: 0.8333\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5510 - accuracy: 0.8810 - val_loss: 0.5394 - val_accuracy: 0.8095\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 304us/step - loss: 0.5502 - accuracy: 0.8750 - val_loss: 0.5304 - val_accuracy: 0.8095\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5381 - accuracy: 0.8929 - val_loss: 0.5512 - val_accuracy: 0.8810\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5362 - accuracy: 0.8750 - val_loss: 0.5402 - val_accuracy: 0.8810\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.5271 - accuracy: 0.8869 - val_loss: 0.5163 - val_accuracy: 0.7857\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5277 - accuracy: 0.8690 - val_loss: 0.5197 - val_accuracy: 0.7857\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 285us/step - loss: 0.5161 - accuracy: 0.8869 - val_loss: 0.5182 - val_accuracy: 0.8095\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5204 - accuracy: 0.8512 - val_loss: 0.5013 - val_accuracy: 0.8095\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5094 - accuracy: 0.8750 - val_loss: 0.5160 - val_accuracy: 0.8810\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5014 - accuracy: 0.8869 - val_loss: 0.5057 - val_accuracy: 0.8571\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4981 - accuracy: 0.8750 - val_loss: 0.4884 - val_accuracy: 0.7857\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4976 - accuracy: 0.8631 - val_loss: 0.4820 - val_accuracy: 0.8095\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4839 - accuracy: 0.8988 - val_loss: 0.4898 - val_accuracy: 0.8333\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4785 - accuracy: 0.8810 - val_loss: 0.4882 - val_accuracy: 0.8571\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4756 - accuracy: 0.8631 - val_loss: 0.4794 - val_accuracy: 0.8333\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4760 - accuracy: 0.8750 - val_loss: 0.4886 - val_accuracy: 0.8571\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4706 - accuracy: 0.8810 - val_loss: 0.4795 - val_accuracy: 0.8333\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 297us/step - loss: 0.4619 - accuracy: 0.8631 - val_loss: 0.4680 - val_accuracy: 0.8095\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4584 - accuracy: 0.8810 - val_loss: 0.4619 - val_accuracy: 0.7857\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 310us/step - loss: 0.4527 - accuracy: 0.8750 - val_loss: 0.4597 - val_accuracy: 0.7619\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4572 - accuracy: 0.8690 - val_loss: 0.4563 - val_accuracy: 0.8333\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.4464 - accuracy: 0.8750 - val_loss: 0.4496 - val_accuracy: 0.8333\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4405 - accuracy: 0.8929 - val_loss: 0.4416 - val_accuracy: 0.8095\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 297us/step - loss: 0.4384 - accuracy: 0.9107 - val_loss: 0.4404 - val_accuracy: 0.8095\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 321us/step - loss: 0.4360 - accuracy: 0.8631 - val_loss: 0.4572 - val_accuracy: 0.8810\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4432 - accuracy: 0.8631 - val_loss: 0.4545 - val_accuracy: 0.8571\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 315us/step - loss: 0.4264 - accuracy: 0.8869 - val_loss: 0.4295 - val_accuracy: 0.8095\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4263 - accuracy: 0.8810 - val_loss: 0.4301 - val_accuracy: 0.8095\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4183 - accuracy: 0.8690 - val_loss: 0.4251 - val_accuracy: 0.8095\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4123 - accuracy: 0.8810 - val_loss: 0.4293 - val_accuracy: 0.8095\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4114 - accuracy: 0.8810 - val_loss: 0.4295 - val_accuracy: 0.8333\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4056 - accuracy: 0.8750 - val_loss: 0.4176 - val_accuracy: 0.8095\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4071 - accuracy: 0.8988 - val_loss: 0.4091 - val_accuracy: 0.8095\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4012 - accuracy: 0.8869 - val_loss: 0.4203 - val_accuracy: 0.8571\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3959 - accuracy: 0.8631 - val_loss: 0.4247 - val_accuracy: 0.8333\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 308us/step - loss: 0.3919 - accuracy: 0.8810 - val_loss: 0.4058 - val_accuracy: 0.8095\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3878 - accuracy: 0.8750 - val_loss: 0.3999 - val_accuracy: 0.8095\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3917 - accuracy: 0.8869 - val_loss: 0.3990 - val_accuracy: 0.8095\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3904 - accuracy: 0.8869 - val_loss: 0.4205 - val_accuracy: 0.8810\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3900 - accuracy: 0.8750 - val_loss: 0.3981 - val_accuracy: 0.8095\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3773 - accuracy: 0.8631 - val_loss: 0.4020 - val_accuracy: 0.8333\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3763 - accuracy: 0.8810 - val_loss: 0.4022 - val_accuracy: 0.8810\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 344us/step - loss: 0.3747 - accuracy: 0.8810 - val_loss: 0.3923 - val_accuracy: 0.8095\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 0s 285us/step - loss: 0.3750 - accuracy: 0.9048 - val_loss: 0.4082 - val_accuracy: 0.8571\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3694 - accuracy: 0.8929 - val_loss: 0.3784 - val_accuracy: 0.8095\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3713 - accuracy: 0.8869 - val_loss: 0.3794 - val_accuracy: 0.8095\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3613 - accuracy: 0.8810 - val_loss: 0.3789 - val_accuracy: 0.8333\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3565 - accuracy: 0.8988 - val_loss: 0.3784 - val_accuracy: 0.8333\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3528 - accuracy: 0.8750 - val_loss: 0.3875 - val_accuracy: 0.8810\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3519 - accuracy: 0.8690 - val_loss: 0.3739 - val_accuracy: 0.8095\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3472 - accuracy: 0.8810 - val_loss: 0.3697 - val_accuracy: 0.8095\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3451 - accuracy: 0.8929 - val_loss: 0.3761 - val_accuracy: 0.8333\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 353us/step - loss: 0.3413 - accuracy: 0.8810 - val_loss: 0.3644 - val_accuracy: 0.8095\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3403 - accuracy: 0.8869 - val_loss: 0.3616 - val_accuracy: 0.8095\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 316us/step - loss: 0.3372 - accuracy: 0.9048 - val_loss: 0.3684 - val_accuracy: 0.8333\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3374 - accuracy: 0.8988 - val_loss: 0.3713 - val_accuracy: 0.8810\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3344 - accuracy: 0.8869 - val_loss: 0.3580 - val_accuracy: 0.8333\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3275 - accuracy: 0.8988 - val_loss: 0.3597 - val_accuracy: 0.8095\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3334 - accuracy: 0.8929 - val_loss: 0.3543 - val_accuracy: 0.8095\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 457us/step - loss: 0.3207 - accuracy: 0.9167 - val_loss: 0.3694 - val_accuracy: 0.8333\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 244us/step - loss: 0.3370 - accuracy: 0.8690 - val_loss: 0.3606 - val_accuracy: 0.8810\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3213 - accuracy: 0.8988 - val_loss: 0.3425 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3162 - accuracy: 0.9048 - val_loss: 0.3475 - val_accuracy: 0.8333\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3296 - accuracy: 0.8929 - val_loss: 0.3527 - val_accuracy: 0.8333\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3178 - accuracy: 0.9048 - val_loss: 0.3636 - val_accuracy: 0.8810\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3396 - accuracy: 0.8929 - val_loss: 0.3401 - val_accuracy: 0.8095\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3163 - accuracy: 0.9107 - val_loss: 0.3399 - val_accuracy: 0.8333\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3160 - accuracy: 0.9048 - val_loss: 0.3543 - val_accuracy: 0.8810\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3093 - accuracy: 0.9107 - val_loss: 0.3606 - val_accuracy: 0.8571\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3058 - accuracy: 0.8929 - val_loss: 0.3285 - val_accuracy: 0.8333\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 242us/step - loss: 0.3001 - accuracy: 0.9048 - val_loss: 0.3279 - val_accuracy: 0.8571\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2968 - accuracy: 0.9107 - val_loss: 0.3263 - val_accuracy: 0.8571\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 558us/step - loss: 0.2973 - accuracy: 0.9048 - val_loss: 0.3278 - val_accuracy: 0.8571\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2956 - accuracy: 0.8929 - val_loss: 0.3292 - val_accuracy: 0.8571\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2890 - accuracy: 0.9226 - val_loss: 0.3326 - val_accuracy: 0.8810\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2919 - accuracy: 0.9167 - val_loss: 0.3216 - val_accuracy: 0.8571\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 313us/step - loss: 0.2868 - accuracy: 0.8929 - val_loss: 0.3426 - val_accuracy: 0.8810\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 208us/step - loss: 0.2885 - accuracy: 0.9167 - val_loss: 0.3208 - val_accuracy: 0.8810\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2818 - accuracy: 0.9167 - val_loss: 0.3168 - val_accuracy: 0.8571\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2792 - accuracy: 0.9107 - val_loss: 0.3297 - val_accuracy: 0.8571\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2802 - accuracy: 0.9048 - val_loss: 0.3186 - val_accuracy: 0.8810\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2796 - accuracy: 0.9107 - val_loss: 0.3068 - val_accuracy: 0.8810\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2746 - accuracy: 0.9167 - val_loss: 0.3163 - val_accuracy: 0.8810\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2725 - accuracy: 0.9167 - val_loss: 0.3270 - val_accuracy: 0.8571\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2747 - accuracy: 0.9226 - val_loss: 0.3172 - val_accuracy: 0.8571\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2710 - accuracy: 0.9107 - val_loss: 0.3033 - val_accuracy: 0.8810\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2667 - accuracy: 0.9107 - val_loss: 0.3157 - val_accuracy: 0.8810\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 374us/step - loss: 0.2871 - accuracy: 0.9107 - val_loss: 0.3597 - val_accuracy: 0.9048\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 199us/step - loss: 0.2729 - accuracy: 0.9048 - val_loss: 0.2942 - val_accuracy: 0.8571\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2638 - accuracy: 0.9167 - val_loss: 0.3092 - val_accuracy: 0.8571\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2630 - accuracy: 0.9226 - val_loss: 0.3064 - val_accuracy: 0.8810\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2573 - accuracy: 0.9167 - val_loss: 0.3007 - val_accuracy: 0.8571\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2589 - accuracy: 0.9107 - val_loss: 0.3024 - val_accuracy: 0.8810\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2579 - accuracy: 0.9167 - val_loss: 0.3198 - val_accuracy: 0.8333\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 281us/step - loss: 0.2576 - accuracy: 0.9226 - val_loss: 0.2963 - val_accuracy: 0.8571\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 300us/step - loss: 0.2550 - accuracy: 0.9048 - val_loss: 0.2912 - val_accuracy: 0.8571\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2603 - accuracy: 0.9226 - val_loss: 0.2847 - val_accuracy: 0.8810\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2549 - accuracy: 0.9107 - val_loss: 0.3002 - val_accuracy: 0.8810\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2490 - accuracy: 0.9226 - val_loss: 0.3072 - val_accuracy: 0.8571\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2512 - accuracy: 0.9167 - val_loss: 0.3025 - val_accuracy: 0.8571\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2434 - accuracy: 0.9286 - val_loss: 0.2832 - val_accuracy: 0.8571\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2457 - accuracy: 0.9286 - val_loss: 0.2881 - val_accuracy: 0.8810\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2462 - accuracy: 0.9107 - val_loss: 0.3035 - val_accuracy: 0.8571\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2436 - accuracy: 0.9167 - val_loss: 0.2932 - val_accuracy: 0.8571\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2374 - accuracy: 0.9345 - val_loss: 0.2936 - val_accuracy: 0.8810\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2455 - accuracy: 0.9167 - val_loss: 0.2783 - val_accuracy: 0.8810\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 284us/step - loss: 0.2384 - accuracy: 0.9226 - val_loss: 0.2944 - val_accuracy: 0.8571\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2544 - accuracy: 0.9107 - val_loss: 0.3042 - val_accuracy: 0.8333\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2396 - accuracy: 0.9167 - val_loss: 0.2980 - val_accuracy: 0.8333\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2403 - accuracy: 0.9226 - val_loss: 0.2846 - val_accuracy: 0.8810\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2464 - accuracy: 0.9048 - val_loss: 0.2736 - val_accuracy: 0.8810\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2337 - accuracy: 0.9226 - val_loss: 0.2954 - val_accuracy: 0.8571\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 357us/step - loss: 0.2326 - accuracy: 0.9226 - val_loss: 0.2806 - val_accuracy: 0.8810\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.2363 - accuracy: 0.9107 - val_loss: 0.2783 - val_accuracy: 0.8810\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 550us/step - loss: 0.2395 - accuracy: 0.9107 - val_loss: 0.2755 - val_accuracy: 0.8810\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.96 - 0s 186us/step - loss: 0.2281 - accuracy: 0.9345 - val_loss: 0.2858 - val_accuracy: 0.8571\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2289 - accuracy: 0.9286 - val_loss: 0.2772 - val_accuracy: 0.8810\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 186us/step - loss: 0.2349 - accuracy: 0.9226 - val_loss: 0.2783 - val_accuracy: 0.8810\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2270 - accuracy: 0.9286 - val_loss: 0.3104 - val_accuracy: 0.8571\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2300 - accuracy: 0.9107 - val_loss: 0.2819 - val_accuracy: 0.8571\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2246 - accuracy: 0.9345 - val_loss: 0.2680 - val_accuracy: 0.8810\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2249 - accuracy: 0.9226 - val_loss: 0.2807 - val_accuracy: 0.8571\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 362us/step - loss: 0.2240 - accuracy: 0.9345 - val_loss: 0.2820 - val_accuracy: 0.8571\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 201us/step - loss: 0.2198 - accuracy: 0.9286 - val_loss: 0.2647 - val_accuracy: 0.8810\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 315us/step - loss: 0.2254 - accuracy: 0.9286 - val_loss: 0.2731 - val_accuracy: 0.8810\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 651us/step - loss: 0.2217 - accuracy: 0.9167 - val_loss: 0.3030 - val_accuracy: 0.8333\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2255 - accuracy: 0.9167 - val_loss: 0.2796 - val_accuracy: 0.8571\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2193 - accuracy: 0.9345 - val_loss: 0.2735 - val_accuracy: 0.8571\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 366us/step - loss: 0.2196 - accuracy: 0.9226 - val_loss: 0.2648 - val_accuracy: 0.8810\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 263us/step - loss: 0.2239 - accuracy: 0.9167 - val_loss: 0.2614 - val_accuracy: 0.8810\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 314us/step - loss: 0.2156 - accuracy: 0.9286 - val_loss: 0.2742 - val_accuracy: 0.8571\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2175 - accuracy: 0.9345 - val_loss: 0.2762 - val_accuracy: 0.8571\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2141 - accuracy: 0.9345 - val_loss: 0.2738 - val_accuracy: 0.8571\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2207 - accuracy: 0.9286 - val_loss: 0.2968 - val_accuracy: 0.8571\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2145 - accuracy: 0.9345 - val_loss: 0.2671 - val_accuracy: 0.8810\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2243 - accuracy: 0.9226 - val_loss: 0.2591 - val_accuracy: 0.8810\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2152 - accuracy: 0.9167 - val_loss: 0.2781 - val_accuracy: 0.8571\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2124 - accuracy: 0.9226 - val_loss: 0.2741 - val_accuracy: 0.8571\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2108 - accuracy: 0.9405 - val_loss: 0.2886 - val_accuracy: 0.8571\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 0s 387us/step - loss: 0.2158 - accuracy: 0.9345 - val_loss: 0.2744 - val_accuracy: 0.8571\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2060 - accuracy: 0.9345 - val_loss: 0.2554 - val_accuracy: 0.9048\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2240 - accuracy: 0.9345 - val_loss: 0.2566 - val_accuracy: 0.9048\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2122 - accuracy: 0.9464 - val_loss: 0.2902 - val_accuracy: 0.8810\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2223 - accuracy: 0.9107 - val_loss: 0.2988 - val_accuracy: 0.8810\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2110 - accuracy: 0.9286 - val_loss: 0.2634 - val_accuracy: 0.8571\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 0s 329us/step - loss: 0.2099 - accuracy: 0.9345 - val_loss: 0.2626 - val_accuracy: 0.8810\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 0s 327us/step - loss: 0.2093 - accuracy: 0.9286 - val_loss: 0.2752 - val_accuracy: 0.8571\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 0s 327us/step - loss: 0.2010 - accuracy: 0.9405 - val_loss: 0.2553 - val_accuracy: 0.9048\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.2094 - accuracy: 0.9345 - val_loss: 0.2597 - val_accuracy: 0.8810\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 0s 278us/step - loss: 0.2138 - accuracy: 0.9345 - val_loss: 0.3107 - val_accuracy: 0.8810\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2153 - accuracy: 0.9464 - val_loss: 0.2839 - val_accuracy: 0.8333\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1999 - accuracy: 0.9286 - val_loss: 0.2554 - val_accuracy: 0.9048\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2070 - accuracy: 0.9286 - val_loss: 0.2625 - val_accuracy: 0.8810\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2073 - accuracy: 0.9286 - val_loss: 0.2902 - val_accuracy: 0.8571\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2040 - accuracy: 0.9345 - val_loss: 0.2555 - val_accuracy: 0.8810\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2053 - accuracy: 0.9286 - val_loss: 0.2530 - val_accuracy: 0.9048\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 370us/step - loss: 0.2124 - accuracy: 0.9286 - val_loss: 0.2841 - val_accuracy: 0.8571\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2028 - accuracy: 0.9286 - val_loss: 0.2555 - val_accuracy: 0.8810\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2003 - accuracy: 0.9345 - val_loss: 0.2617 - val_accuracy: 0.8571\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1957 - accuracy: 0.9405 - val_loss: 0.2633 - val_accuracy: 0.8571\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1971 - accuracy: 0.9405 - val_loss: 0.2672 - val_accuracy: 0.8571\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1959 - accuracy: 0.9405 - val_loss: 0.2695 - val_accuracy: 0.8571\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1984 - accuracy: 0.9286 - val_loss: 0.2601 - val_accuracy: 0.8571\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 0s 364us/step - loss: 0.1938 - accuracy: 0.9405 - val_loss: 0.2795 - val_accuracy: 0.8571\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 0s 271us/step - loss: 0.2052 - accuracy: 0.9286 - val_loss: 0.2838 - val_accuracy: 0.8571\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 0s 421us/step - loss: 0.1941 - accuracy: 0.9345 - val_loss: 0.2541 - val_accuracy: 0.8810\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 0s 235us/step - loss: 0.1983 - accuracy: 0.9226 - val_loss: 0.2564 - val_accuracy: 0.8571\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2073 - accuracy: 0.9167 - val_loss: 0.2676 - val_accuracy: 0.8333\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2034 - accuracy: 0.9226 - val_loss: 0.2721 - val_accuracy: 0.8571\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1934 - accuracy: 0.9405 - val_loss: 0.2576 - val_accuracy: 0.8571\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1945 - accuracy: 0.9464 - val_loss: 0.2627 - val_accuracy: 0.8571\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1997 - accuracy: 0.9286 - val_loss: 0.2574 - val_accuracy: 0.8571\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.1984 - accuracy: 0.9405 - val_loss: 0.2695 - val_accuracy: 0.8571\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 0s 361us/step - loss: 0.1962 - accuracy: 0.9286 - val_loss: 0.2461 - val_accuracy: 0.9048\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2079 - accuracy: 0.9286 - val_loss: 0.2540 - val_accuracy: 0.8810\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2032 - accuracy: 0.9048 - val_loss: 0.2565 - val_accuracy: 0.8810\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1920 - accuracy: 0.9405 - val_loss: 0.2759 - val_accuracy: 0.8333\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2062 - accuracy: 0.9167 - val_loss: 0.2961 - val_accuracy: 0.8810\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2008 - accuracy: 0.9345 - val_loss: 0.2623 - val_accuracy: 0.8571\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1984 - accuracy: 0.9226 - val_loss: 0.2507 - val_accuracy: 0.8571\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 582us/step - loss: 0.1880 - accuracy: 0.9405 - val_loss: 0.2749 - val_accuracy: 0.8571\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 323us/step - loss: 0.1901 - accuracy: 0.9464 - val_loss: 0.2568 - val_accuracy: 0.8571\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1908 - accuracy: 0.9345 - val_loss: 0.2480 - val_accuracy: 0.9048\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1931 - accuracy: 0.9286 - val_loss: 0.2706 - val_accuracy: 0.8571\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1923 - accuracy: 0.9286 - val_loss: 0.2700 - val_accuracy: 0.8571\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1943 - accuracy: 0.9345 - val_loss: 0.2861 - val_accuracy: 0.8810\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1879 - accuracy: 0.9524 - val_loss: 0.2551 - val_accuracy: 0.8571\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1969 - accuracy: 0.9226 - val_loss: 0.2497 - val_accuracy: 0.9048\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2065 - accuracy: 0.9226 - val_loss: 0.2581 - val_accuracy: 0.8571\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1902 - accuracy: 0.9405 - val_loss: 0.2717 - val_accuracy: 0.8571\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 339us/step - loss: 0.1864 - accuracy: 0.9405 - val_loss: 0.2604 - val_accuracy: 0.8571\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 261us/step - loss: 0.1873 - accuracy: 0.9405 - val_loss: 0.2624 - val_accuracy: 0.8571\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 214us/step - loss: 0.1887 - accuracy: 0.9345 - val_loss: 0.2538 - val_accuracy: 0.8571\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1846 - accuracy: 0.9405 - val_loss: 0.2681 - val_accuracy: 0.8571\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1885 - accuracy: 0.9345 - val_loss: 0.2605 - val_accuracy: 0.8571\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1857 - accuracy: 0.9405 - val_loss: 0.2580 - val_accuracy: 0.8571\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2027 - accuracy: 0.9167 - val_loss: 0.2529 - val_accuracy: 0.8333\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 452us/step - loss: 0.1845 - accuracy: 0.9345 - val_loss: 0.2664 - val_accuracy: 0.8571\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 242us/step - loss: 0.1858 - accuracy: 0.9286 - val_loss: 0.2591 - val_accuracy: 0.8571\n",
      "Train on 168 samples, validate on 42 samples\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 1.4483 - accuracy: 0.3512 - val_loss: 1.4421 - val_accuracy: 0.2619\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 226us/step - loss: 1.3505 - accuracy: 0.3512 - val_loss: 1.3454 - val_accuracy: 0.2619\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.2618 - accuracy: 0.3512 - val_loss: 1.2554 - val_accuracy: 0.2619\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 260us/step - loss: 1.1821 - accuracy: 0.3512 - val_loss: 1.1828 - val_accuracy: 0.2619\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.1149 - accuracy: 0.3512 - val_loss: 1.1296 - val_accuracy: 0.2619\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0846 - accuracy: 0.3512 - val_loss: 1.1032 - val_accuracy: 0.2619\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 315us/step - loss: 1.0711 - accuracy: 0.3512 - val_loss: 1.0907 - val_accuracy: 0.2619\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 1.0594 - accuracy: 0.3512 - val_loss: 1.0828 - val_accuracy: 0.2619\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0511 - accuracy: 0.3512 - val_loss: 1.0775 - val_accuracy: 0.2619\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 1.0407 - accuracy: 0.3571 - val_loss: 1.0630 - val_accuracy: 0.2857\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0297 - accuracy: 0.3452 - val_loss: 1.0424 - val_accuracy: 0.1905\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0177 - accuracy: 0.2857 - val_loss: 1.0190 - val_accuracy: 0.2857\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0057 - accuracy: 0.3869 - val_loss: 1.0041 - val_accuracy: 0.4762\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9945 - accuracy: 0.4702 - val_loss: 0.9923 - val_accuracy: 0.5714\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9844 - accuracy: 0.4940 - val_loss: 0.9775 - val_accuracy: 0.5952\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9752 - accuracy: 0.5179 - val_loss: 0.9667 - val_accuracy: 0.6429\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 0s 396us/step - loss: 0.9652 - accuracy: 0.5298 - val_loss: 0.9537 - val_accuracy: 0.6429\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 312us/step - loss: 0.9567 - accuracy: 0.5417 - val_loss: 0.9384 - val_accuracy: 0.6429\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9471 - accuracy: 0.5417 - val_loss: 0.9258 - val_accuracy: 0.6190\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.9387 - accuracy: 0.5417 - val_loss: 0.9191 - val_accuracy: 0.6429\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.9306 - accuracy: 0.5417 - val_loss: 0.9112 - val_accuracy: 0.6429\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9235 - accuracy: 0.5357 - val_loss: 0.9016 - val_accuracy: 0.6429\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9133 - accuracy: 0.5476 - val_loss: 0.8906 - val_accuracy: 0.6429\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 409us/step - loss: 0.9054 - accuracy: 0.5417 - val_loss: 0.8807 - val_accuracy: 0.6429\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 0s 298us/step - loss: 0.8967 - accuracy: 0.5417 - val_loss: 0.8698 - val_accuracy: 0.6190\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 261us/step - loss: 0.8891 - accuracy: 0.5417 - val_loss: 0.8674 - val_accuracy: 0.6429\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8833 - accuracy: 0.5476 - val_loss: 0.8628 - val_accuracy: 0.6429\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.8773 - accuracy: 0.5417 - val_loss: 0.8526 - val_accuracy: 0.6190\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.8702 - accuracy: 0.5417 - val_loss: 0.8441 - val_accuracy: 0.6429\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8641 - accuracy: 0.5536 - val_loss: 0.8343 - val_accuracy: 0.6190\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8593 - accuracy: 0.5655 - val_loss: 0.8244 - val_accuracy: 0.6190\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8526 - accuracy: 0.5536 - val_loss: 0.8144 - val_accuracy: 0.6429\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.8396 - accuracy: 0.5536 - val_loss: 0.7953 - val_accuracy: 0.6190\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8346 - accuracy: 0.5595 - val_loss: 0.7881 - val_accuracy: 0.6190\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 295us/step - loss: 0.8217 - accuracy: 0.5595 - val_loss: 0.7984 - val_accuracy: 0.6429\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 284us/step - loss: 0.8240 - accuracy: 0.5417 - val_loss: 0.8034 - val_accuracy: 0.6429\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8121 - accuracy: 0.5536 - val_loss: 0.7733 - val_accuracy: 0.6190\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.8095 - accuracy: 0.5714 - val_loss: 0.7654 - val_accuracy: 0.6190\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8061 - accuracy: 0.5595 - val_loss: 0.7785 - val_accuracy: 0.6429\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8037 - accuracy: 0.5536 - val_loss: 0.7798 - val_accuracy: 0.6905\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8040 - accuracy: 0.6012 - val_loss: 0.7613 - val_accuracy: 0.7143\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 327us/step - loss: 0.7995 - accuracy: 0.5774 - val_loss: 0.7595 - val_accuracy: 0.6190\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 322us/step - loss: 0.7922 - accuracy: 0.5655 - val_loss: 0.7651 - val_accuracy: 0.6667\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 198us/step - loss: 0.7907 - accuracy: 0.5595 - val_loss: 0.7621 - val_accuracy: 0.6905\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7861 - accuracy: 0.5655 - val_loss: 0.7523 - val_accuracy: 0.6429\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7887 - accuracy: 0.5774 - val_loss: 0.7466 - val_accuracy: 0.6190\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7843 - accuracy: 0.5774 - val_loss: 0.7444 - val_accuracy: 0.6429\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.7823 - accuracy: 0.5774 - val_loss: 0.7435 - val_accuracy: 0.6429\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7776 - accuracy: 0.5595 - val_loss: 0.7535 - val_accuracy: 0.6429\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7781 - accuracy: 0.5595 - val_loss: 0.7396 - val_accuracy: 0.6429\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7772 - accuracy: 0.5714 - val_loss: 0.7331 - val_accuracy: 0.6190\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7764 - accuracy: 0.5774 - val_loss: 0.7321 - val_accuracy: 0.6429\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 306us/step - loss: 0.7720 - accuracy: 0.5536 - val_loss: 0.7395 - val_accuracy: 0.6429\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 312us/step - loss: 0.7693 - accuracy: 0.5595 - val_loss: 0.7368 - val_accuracy: 0.6667\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7670 - accuracy: 0.5595 - val_loss: 0.7330 - val_accuracy: 0.6667\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7674 - accuracy: 0.5714 - val_loss: 0.7265 - val_accuracy: 0.6190\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7638 - accuracy: 0.5774 - val_loss: 0.7280 - val_accuracy: 0.6667\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7608 - accuracy: 0.5714 - val_loss: 0.7346 - val_accuracy: 0.6429\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7650 - accuracy: 0.5536 - val_loss: 0.7405 - val_accuracy: 0.6429\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 308us/step - loss: 0.7594 - accuracy: 0.5714 - val_loss: 0.7275 - val_accuracy: 0.6667\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7563 - accuracy: 0.5893 - val_loss: 0.7246 - val_accuracy: 0.6429\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7555 - accuracy: 0.5833 - val_loss: 0.7239 - val_accuracy: 0.6429\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7534 - accuracy: 0.5833 - val_loss: 0.7254 - val_accuracy: 0.6667\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7579 - accuracy: 0.5655 - val_loss: 0.7270 - val_accuracy: 0.6667\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7550 - accuracy: 0.5833 - val_loss: 0.7162 - val_accuracy: 0.6190\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7578 - accuracy: 0.5774 - val_loss: 0.7148 - val_accuracy: 0.6190\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7507 - accuracy: 0.5774 - val_loss: 0.7161 - val_accuracy: 0.6667\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7471 - accuracy: 0.5774 - val_loss: 0.7215 - val_accuracy: 0.6667\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7464 - accuracy: 0.5714 - val_loss: 0.7161 - val_accuracy: 0.6667\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 304us/step - loss: 0.7450 - accuracy: 0.5893 - val_loss: 0.7120 - val_accuracy: 0.6429\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 232us/step - loss: 0.7503 - accuracy: 0.5774 - val_loss: 0.7102 - val_accuracy: 0.6190\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 213us/step - loss: 0.7448 - accuracy: 0.5774 - val_loss: 0.7103 - val_accuracy: 0.6667\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.8426 - accuracy: 0.59 - 0s 279us/step - loss: 0.7412 - accuracy: 0.5833 - val_loss: 0.7119 - val_accuracy: 0.6667\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7403 - accuracy: 0.5833 - val_loss: 0.7072 - val_accuracy: 0.6667\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7387 - accuracy: 0.5893 - val_loss: 0.7061 - val_accuracy: 0.6667\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7385 - accuracy: 0.5893 - val_loss: 0.7058 - val_accuracy: 0.6667\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 351us/step - loss: 0.7367 - accuracy: 0.5893 - val_loss: 0.7034 - val_accuracy: 0.6429\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 363us/step - loss: 0.7368 - accuracy: 0.5893 - val_loss: 0.7010 - val_accuracy: 0.6667\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 375us/step - loss: 0.7337 - accuracy: 0.5893 - val_loss: 0.7000 - val_accuracy: 0.6667\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 327us/step - loss: 0.7334 - accuracy: 0.5833 - val_loss: 0.7076 - val_accuracy: 0.6667\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 315us/step - loss: 0.7350 - accuracy: 0.5714 - val_loss: 0.7025 - val_accuracy: 0.6667\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7320 - accuracy: 0.5655 - val_loss: 0.7044 - val_accuracy: 0.6667\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7306 - accuracy: 0.5774 - val_loss: 0.6983 - val_accuracy: 0.6667\n",
      "Epoch 84/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.7269 - accuracy: 0.5893 - val_loss: 0.6921 - val_accuracy: 0.6667\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7301 - accuracy: 0.5893 - val_loss: 0.6907 - val_accuracy: 0.6667\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7297 - accuracy: 0.5893 - val_loss: 0.6936 - val_accuracy: 0.6667\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 258us/step - loss: 0.7248 - accuracy: 0.5893 - val_loss: 0.6884 - val_accuracy: 0.6667\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 319us/step - loss: 0.7225 - accuracy: 0.5893 - val_loss: 0.6859 - val_accuracy: 0.6667\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7225 - accuracy: 0.5893 - val_loss: 0.6843 - val_accuracy: 0.6667\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7209 - accuracy: 0.5893 - val_loss: 0.6841 - val_accuracy: 0.6667\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7192 - accuracy: 0.5893 - val_loss: 0.6833 - val_accuracy: 0.6667\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7202 - accuracy: 0.5893 - val_loss: 0.6835 - val_accuracy: 0.6667\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 0s 388us/step - loss: 0.7214 - accuracy: 0.5774 - val_loss: 0.6957 - val_accuracy: 0.6667\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.7205 - accuracy: 0.5714 - val_loss: 0.6832 - val_accuracy: 0.6667\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 222us/step - loss: 0.7138 - accuracy: 0.5893 - val_loss: 0.6789 - val_accuracy: 0.6667\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7144 - accuracy: 0.5893 - val_loss: 0.6756 - val_accuracy: 0.6667\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7111 - accuracy: 0.5893 - val_loss: 0.6758 - val_accuracy: 0.6667\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7136 - accuracy: 0.5952 - val_loss: 0.6758 - val_accuracy: 0.6667\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.7089 - accuracy: 0.5952 - val_loss: 0.6745 - val_accuracy: 0.6905\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7096 - accuracy: 0.6131 - val_loss: 0.6746 - val_accuracy: 0.7381\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7070 - accuracy: 0.6607 - val_loss: 0.6742 - val_accuracy: 0.7381\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7067 - accuracy: 0.6548 - val_loss: 0.6774 - val_accuracy: 0.7143\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7054 - accuracy: 0.6607 - val_loss: 0.6726 - val_accuracy: 0.7381\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 300us/step - loss: 0.7034 - accuracy: 0.6845 - val_loss: 0.6722 - val_accuracy: 0.8095\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 314us/step - loss: 0.7043 - accuracy: 0.7857 - val_loss: 0.6717 - val_accuracy: 0.8095\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7016 - accuracy: 0.7798 - val_loss: 0.6693 - val_accuracy: 0.7619\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6991 - accuracy: 0.6667 - val_loss: 0.6648 - val_accuracy: 0.6905\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6977 - accuracy: 0.6012 - val_loss: 0.6606 - val_accuracy: 0.6905\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6959 - accuracy: 0.6131 - val_loss: 0.6589 - val_accuracy: 0.6905\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 310us/step - loss: 0.6945 - accuracy: 0.6429 - val_loss: 0.6589 - val_accuracy: 0.7143\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 369us/step - loss: 0.6941 - accuracy: 0.6607 - val_loss: 0.6577 - val_accuracy: 0.7143\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.6924 - accuracy: 0.6310 - val_loss: 0.6554 - val_accuracy: 0.7143\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 256us/step - loss: 0.6948 - accuracy: 0.6548 - val_loss: 0.6542 - val_accuracy: 0.7143\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.6891 - accuracy: 0.6369 - val_loss: 0.6516 - val_accuracy: 0.7143\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 298us/step - loss: 0.6892 - accuracy: 0.6250 - val_loss: 0.6499 - val_accuracy: 0.6905\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 309us/step - loss: 0.6858 - accuracy: 0.6190 - val_loss: 0.6513 - val_accuracy: 0.7143\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 222us/step - loss: 0.6862 - accuracy: 0.6369 - val_loss: 0.6472 - val_accuracy: 0.7143\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6821 - accuracy: 0.6429 - val_loss: 0.6456 - val_accuracy: 0.7143\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6825 - accuracy: 0.6488 - val_loss: 0.6450 - val_accuracy: 0.7143\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6790 - accuracy: 0.6369 - val_loss: 0.6442 - val_accuracy: 0.7143\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 362us/step - loss: 0.6826 - accuracy: 0.5952 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 199us/step - loss: 0.6789 - accuracy: 0.5952 - val_loss: 0.6357 - val_accuracy: 0.6667\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 310us/step - loss: 0.6760 - accuracy: 0.5952 - val_loss: 0.6346 - val_accuracy: 0.6667\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6732 - accuracy: 0.5952 - val_loss: 0.6344 - val_accuracy: 0.6905\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.6723 - accuracy: 0.6310 - val_loss: 0.6348 - val_accuracy: 0.7143\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6692 - accuracy: 0.6369 - val_loss: 0.6324 - val_accuracy: 0.6905\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6677 - accuracy: 0.6369 - val_loss: 0.6327 - val_accuracy: 0.7381\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 317us/step - loss: 0.6653 - accuracy: 0.6488 - val_loss: 0.6311 - val_accuracy: 0.7857\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6657 - accuracy: 0.6964 - val_loss: 0.6292 - val_accuracy: 0.7619\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6627 - accuracy: 0.6786 - val_loss: 0.6281 - val_accuracy: 0.7857\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6612 - accuracy: 0.6429 - val_loss: 0.6221 - val_accuracy: 0.7143\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6588 - accuracy: 0.6845 - val_loss: 0.6233 - val_accuracy: 0.8095\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6597 - accuracy: 0.7560 - val_loss: 0.6197 - val_accuracy: 0.8095\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6576 - accuracy: 0.7679 - val_loss: 0.6174 - val_accuracy: 0.7857\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6529 - accuracy: 0.7143 - val_loss: 0.6147 - val_accuracy: 0.8095\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6503 - accuracy: 0.6429 - val_loss: 0.6107 - val_accuracy: 0.7619\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6469 - accuracy: 0.6548 - val_loss: 0.6108 - val_accuracy: 0.7857\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 304us/step - loss: 0.6442 - accuracy: 0.7738 - val_loss: 0.6141 - val_accuracy: 0.8810\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 258us/step - loss: 0.6471 - accuracy: 0.8631 - val_loss: 0.6133 - val_accuracy: 0.8810\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 316us/step - loss: 0.6442 - accuracy: 0.8869 - val_loss: 0.6122 - val_accuracy: 0.8333\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6481 - accuracy: 0.8095 - val_loss: 0.6142 - val_accuracy: 0.8571\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6382 - accuracy: 0.8393 - val_loss: 0.6040 - val_accuracy: 0.8333\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6402 - accuracy: 0.6905 - val_loss: 0.6008 - val_accuracy: 0.7619\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6328 - accuracy: 0.7083 - val_loss: 0.6023 - val_accuracy: 0.7619\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6285 - accuracy: 0.7560 - val_loss: 0.6008 - val_accuracy: 0.7619\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 346us/step - loss: 0.6249 - accuracy: 0.7619 - val_loss: 0.5989 - val_accuracy: 0.7381\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.6223 - accuracy: 0.7619 - val_loss: 0.5965 - val_accuracy: 0.7381\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.6197 - accuracy: 0.7738 - val_loss: 0.5946 - val_accuracy: 0.7857\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.6155 - accuracy: 0.7679 - val_loss: 0.5927 - val_accuracy: 0.7857\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 262us/step - loss: 0.6110 - accuracy: 0.7976 - val_loss: 0.5914 - val_accuracy: 0.7619\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 309us/step - loss: 0.6198 - accuracy: 0.7798 - val_loss: 0.6006 - val_accuracy: 0.7619\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.6118 - accuracy: 0.7917 - val_loss: 0.5804 - val_accuracy: 0.7857\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 259us/step - loss: 0.6072 - accuracy: 0.7143 - val_loss: 0.5784 - val_accuracy: 0.7619\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5996 - accuracy: 0.7440 - val_loss: 0.5759 - val_accuracy: 0.7857\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6025 - accuracy: 0.7857 - val_loss: 0.5808 - val_accuracy: 0.7857\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 385us/step - loss: 0.5985 - accuracy: 0.7857 - val_loss: 0.5780 - val_accuracy: 0.8333\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 231us/step - loss: 0.5885 - accuracy: 0.8214 - val_loss: 0.5726 - val_accuracy: 0.8095\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 217us/step - loss: 0.5854 - accuracy: 0.8214 - val_loss: 0.5649 - val_accuracy: 0.8571\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5837 - accuracy: 0.8393 - val_loss: 0.5583 - val_accuracy: 0.8095\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5789 - accuracy: 0.7679 - val_loss: 0.5518 - val_accuracy: 0.7619\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5831 - accuracy: 0.7738 - val_loss: 0.5499 - val_accuracy: 0.8333\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5764 - accuracy: 0.7798 - val_loss: 0.5474 - val_accuracy: 0.8095\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 310us/step - loss: 0.5594 - accuracy: 0.8393 - val_loss: 0.5540 - val_accuracy: 0.8095\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 327us/step - loss: 0.5744 - accuracy: 0.8333 - val_loss: 0.5438 - val_accuracy: 0.8333\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.5602 - accuracy: 0.8393 - val_loss: 0.5362 - val_accuracy: 0.8095\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 241us/step - loss: 0.5550 - accuracy: 0.8155 - val_loss: 0.5387 - val_accuracy: 0.8571\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5589 - accuracy: 0.8571 - val_loss: 0.5361 - val_accuracy: 0.8095\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5491 - accuracy: 0.8631 - val_loss: 0.5234 - val_accuracy: 0.8810\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5463 - accuracy: 0.8512 - val_loss: 0.5201 - val_accuracy: 0.8810\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5446 - accuracy: 0.8571 - val_loss: 0.5203 - val_accuracy: 0.8333\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5354 - accuracy: 0.8869 - val_loss: 0.5115 - val_accuracy: 0.8095\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5367 - accuracy: 0.8095 - val_loss: 0.5064 - val_accuracy: 0.8333\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5282 - accuracy: 0.8690 - val_loss: 0.5075 - val_accuracy: 0.8333\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 374us/step - loss: 0.5241 - accuracy: 0.8631 - val_loss: 0.5018 - val_accuracy: 0.8810\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 294us/step - loss: 0.5227 - accuracy: 0.8690 - val_loss: 0.5010 - val_accuracy: 0.8571\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 312us/step - loss: 0.5168 - accuracy: 0.8631 - val_loss: 0.5105 - val_accuracy: 0.8571\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5171 - accuracy: 0.8869 - val_loss: 0.4926 - val_accuracy: 0.8571\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.5135 - accuracy: 0.8571 - val_loss: 0.4874 - val_accuracy: 0.8810\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.5086 - accuracy: 0.8750 - val_loss: 0.4926 - val_accuracy: 0.8810\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5052 - accuracy: 0.8810 - val_loss: 0.4858 - val_accuracy: 0.8571\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 332us/step - loss: 0.4942 - accuracy: 0.8929 - val_loss: 0.4839 - val_accuracy: 0.8571\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.5022 - accuracy: 0.8690 - val_loss: 0.4799 - val_accuracy: 0.8571\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.4938 - accuracy: 0.8810 - val_loss: 0.4766 - val_accuracy: 0.9048\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 276us/step - loss: 0.4869 - accuracy: 0.8750 - val_loss: 0.4689 - val_accuracy: 0.8571\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.4865 - accuracy: 0.8631 - val_loss: 0.4642 - val_accuracy: 0.8571\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.4793 - accuracy: 0.8810 - val_loss: 0.4561 - val_accuracy: 0.8571\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.4760 - accuracy: 0.8750 - val_loss: 0.4579 - val_accuracy: 0.8571\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 0s 234us/step - loss: 0.4690 - accuracy: 0.8929 - val_loss: 0.4577 - val_accuracy: 0.8810\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4676 - accuracy: 0.8869 - val_loss: 0.4520 - val_accuracy: 0.8810\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4615 - accuracy: 0.8929 - val_loss: 0.4480 - val_accuracy: 0.8810\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4683 - accuracy: 0.8631 - val_loss: 0.4400 - val_accuracy: 0.8571\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 0s 365us/step - loss: 0.4566 - accuracy: 0.8869 - val_loss: 0.4436 - val_accuracy: 0.8571\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4494 - accuracy: 0.8988 - val_loss: 0.4327 - val_accuracy: 0.8571\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 317us/step - loss: 0.4558 - accuracy: 0.8631 - val_loss: 0.4312 - val_accuracy: 0.8810\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4413 - accuracy: 0.8929 - val_loss: 0.4376 - val_accuracy: 0.8810\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4442 - accuracy: 0.8988 - val_loss: 0.4279 - val_accuracy: 0.8810\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4449 - accuracy: 0.8690 - val_loss: 0.4240 - val_accuracy: 0.8571\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4468 - accuracy: 0.8690 - val_loss: 0.4182 - val_accuracy: 0.8571\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 0s 328us/step - loss: 0.4367 - accuracy: 0.8810 - val_loss: 0.4168 - val_accuracy: 0.8333\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.4343 - accuracy: 0.8810 - val_loss: 0.4163 - val_accuracy: 0.8810\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 0s 292us/step - loss: 0.4237 - accuracy: 0.8988 - val_loss: 0.4119 - val_accuracy: 0.8810\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4155 - accuracy: 0.8869 - val_loss: 0.4087 - val_accuracy: 0.8571\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4207 - accuracy: 0.8869 - val_loss: 0.4035 - val_accuracy: 0.9048\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4233 - accuracy: 0.9107 - val_loss: 0.4137 - val_accuracy: 0.8571\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4073 - accuracy: 0.8988 - val_loss: 0.4003 - val_accuracy: 0.8571\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4089 - accuracy: 0.8869 - val_loss: 0.3952 - val_accuracy: 0.8571\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4135 - accuracy: 0.9048 - val_loss: 0.3998 - val_accuracy: 0.8571\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4048 - accuracy: 0.8810 - val_loss: 0.3936 - val_accuracy: 0.8571\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3954 - accuracy: 0.8810 - val_loss: 0.3931 - val_accuracy: 0.8571\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 0s 398us/step - loss: 0.3975 - accuracy: 0.9048 - val_loss: 0.3882 - val_accuracy: 0.8810\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 0s 228us/step - loss: 0.3901 - accuracy: 0.8988 - val_loss: 0.3793 - val_accuracy: 0.9048\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3847 - accuracy: 0.8929 - val_loss: 0.3805 - val_accuracy: 0.8571\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3921 - accuracy: 0.8988 - val_loss: 0.3815 - val_accuracy: 0.8810\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3800 - accuracy: 0.9107 - val_loss: 0.3750 - val_accuracy: 0.9048\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3781 - accuracy: 0.8988 - val_loss: 0.3746 - val_accuracy: 0.8571\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3759 - accuracy: 0.8988 - val_loss: 0.3689 - val_accuracy: 0.9048\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 0s 423us/step - loss: 0.3744 - accuracy: 0.8869 - val_loss: 0.3659 - val_accuracy: 0.9048\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 0s 256us/step - loss: 0.3742 - accuracy: 0.9048 - val_loss: 0.3729 - val_accuracy: 0.8571\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 0s 287us/step - loss: 0.3703 - accuracy: 0.9048 - val_loss: 0.3580 - val_accuracy: 0.8810\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3623 - accuracy: 0.9107 - val_loss: 0.3608 - val_accuracy: 0.8571\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3596 - accuracy: 0.9167 - val_loss: 0.3557 - val_accuracy: 0.9048\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3591 - accuracy: 0.8869 - val_loss: 0.3579 - val_accuracy: 0.9048\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3571 - accuracy: 0.8929 - val_loss: 0.3512 - val_accuracy: 0.9048\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3552 - accuracy: 0.8929 - val_loss: 0.3425 - val_accuracy: 0.8571\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3636 - accuracy: 0.8929 - val_loss: 0.3563 - val_accuracy: 0.8571\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3537 - accuracy: 0.8929 - val_loss: 0.3462 - val_accuracy: 0.8810\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3512 - accuracy: 0.8869 - val_loss: 0.3462 - val_accuracy: 0.9048\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 324us/step - loss: 0.3456 - accuracy: 0.9048 - val_loss: 0.3484 - val_accuracy: 0.8810\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 258us/step - loss: 0.3437 - accuracy: 0.8988 - val_loss: 0.3372 - val_accuracy: 0.8571\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.3407 - accuracy: 0.8988 - val_loss: 0.3401 - val_accuracy: 0.9048\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3360 - accuracy: 0.9048 - val_loss: 0.3342 - val_accuracy: 0.8571\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3330 - accuracy: 0.8988 - val_loss: 0.3347 - val_accuracy: 0.8810\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.3337 - accuracy: 0.8988 - val_loss: 0.3340 - val_accuracy: 0.9048\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 334us/step - loss: 0.3346 - accuracy: 0.9048 - val_loss: 0.3371 - val_accuracy: 0.9048\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 327us/step - loss: 0.3328 - accuracy: 0.8988 - val_loss: 0.3339 - val_accuracy: 0.9048\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 297us/step - loss: 0.3369 - accuracy: 0.8929 - val_loss: 0.3372 - val_accuracy: 0.8571\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3258 - accuracy: 0.8988 - val_loss: 0.3239 - val_accuracy: 0.8810\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3212 - accuracy: 0.9107 - val_loss: 0.3249 - val_accuracy: 0.8810\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3180 - accuracy: 0.8988 - val_loss: 0.3208 - val_accuracy: 0.9048\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.3169 - accuracy: 0.9048 - val_loss: 0.3179 - val_accuracy: 0.8571\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 558us/step - loss: 0.3173 - accuracy: 0.9107 - val_loss: 0.3167 - val_accuracy: 0.8571\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 535us/step - loss: 0.3251 - accuracy: 0.9167 - val_loss: 0.3238 - val_accuracy: 0.8810\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3206 - accuracy: 0.8929 - val_loss: 0.3183 - val_accuracy: 0.9048\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3111 - accuracy: 0.9167 - val_loss: 0.3171 - val_accuracy: 0.8571\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 272us/step - loss: 0.3118 - accuracy: 0.9226 - val_loss: 0.3079 - val_accuracy: 0.8571\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 330us/step - loss: 0.3177 - accuracy: 0.8929 - val_loss: 0.3133 - val_accuracy: 0.9048\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 255us/step - loss: 0.3194 - accuracy: 0.8810 - val_loss: 0.3266 - val_accuracy: 0.8571\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 304us/step - loss: 0.3119 - accuracy: 0.8988 - val_loss: 0.3118 - val_accuracy: 0.9048\n",
      "Epoch 249/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 247us/step - loss: 0.3094 - accuracy: 0.8988 - val_loss: 0.3067 - val_accuracy: 0.8571\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 0s 255us/step - loss: 0.3045 - accuracy: 0.8869 - val_loss: 0.3024 - val_accuracy: 0.8333\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 0s 244us/step - loss: 0.3016 - accuracy: 0.9107 - val_loss: 0.3148 - val_accuracy: 0.8571\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 0s 201us/step - loss: 0.3092 - accuracy: 0.8988 - val_loss: 0.3082 - val_accuracy: 0.9048\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3156 - accuracy: 0.8929 - val_loss: 0.3124 - val_accuracy: 0.9048\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2976 - accuracy: 0.8988 - val_loss: 0.3127 - val_accuracy: 0.8810\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2973 - accuracy: 0.9107 - val_loss: 0.2954 - val_accuracy: 0.8571\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2899 - accuracy: 0.9048 - val_loss: 0.2995 - val_accuracy: 0.8571\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2919 - accuracy: 0.9048 - val_loss: 0.3028 - val_accuracy: 0.9048\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2969 - accuracy: 0.8988 - val_loss: 0.2972 - val_accuracy: 0.8810\n",
      "Epoch 259/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2873 - accuracy: 0.9107 - val_loss: 0.2926 - val_accuracy: 0.8810\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2881 - accuracy: 0.9286 - val_loss: 0.2947 - val_accuracy: 0.8571\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 0s 345us/step - loss: 0.2930 - accuracy: 0.8929 - val_loss: 0.2896 - val_accuracy: 0.8571\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2860 - accuracy: 0.9107 - val_loss: 0.2874 - val_accuracy: 0.8571\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 0s 301us/step - loss: 0.2863 - accuracy: 0.9048 - val_loss: 0.2921 - val_accuracy: 0.8810\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2957 - accuracy: 0.8869 - val_loss: 0.2943 - val_accuracy: 0.8571\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 0s 192us/step - loss: 0.2813 - accuracy: 0.9048 - val_loss: 0.2976 - val_accuracy: 0.9048\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2816 - accuracy: 0.8988 - val_loss: 0.2914 - val_accuracy: 0.8810\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2780 - accuracy: 0.9048 - val_loss: 0.2869 - val_accuracy: 0.8810\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2760 - accuracy: 0.8988 - val_loss: 0.2835 - val_accuracy: 0.8810\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 0s 308us/step - loss: 0.2745 - accuracy: 0.9048 - val_loss: 0.2832 - val_accuracy: 0.8571\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 0s 315us/step - loss: 0.2730 - accuracy: 0.9107 - val_loss: 0.2791 - val_accuracy: 0.8571\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 0s 278us/step - loss: 0.2747 - accuracy: 0.9167 - val_loss: 0.2770 - val_accuracy: 0.8571\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2719 - accuracy: 0.9107 - val_loss: 0.2807 - val_accuracy: 0.8571\n",
      "Epoch 273/1000\n",
      "168/168 [==============================] - 0s 222us/step - loss: 0.2689 - accuracy: 0.9107 - val_loss: 0.2823 - val_accuracy: 0.8810\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2700 - accuracy: 0.9107 - val_loss: 0.2794 - val_accuracy: 0.8810\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2687 - accuracy: 0.8929 - val_loss: 0.2779 - val_accuracy: 0.8810\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2689 - accuracy: 0.9048 - val_loss: 0.2776 - val_accuracy: 0.8571\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2800 - accuracy: 0.9167 - val_loss: 0.2873 - val_accuracy: 0.8571\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2805 - accuracy: 0.8988 - val_loss: 0.2904 - val_accuracy: 0.8571\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2643 - accuracy: 0.9167 - val_loss: 0.2892 - val_accuracy: 0.8571\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2774 - accuracy: 0.9107 - val_loss: 0.2796 - val_accuracy: 0.8810\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2649 - accuracy: 0.9167 - val_loss: 0.2711 - val_accuracy: 0.8571\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 0s 248us/step - loss: 0.2618 - accuracy: 0.9167 - val_loss: 0.2723 - val_accuracy: 0.8571\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2613 - accuracy: 0.9226 - val_loss: 0.2724 - val_accuracy: 0.8810\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 0s 267us/step - loss: 0.2622 - accuracy: 0.8988 - val_loss: 0.2771 - val_accuracy: 0.8810\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2602 - accuracy: 0.8988 - val_loss: 0.2708 - val_accuracy: 0.8810\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2590 - accuracy: 0.9167 - val_loss: 0.2704 - val_accuracy: 0.8810\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2608 - accuracy: 0.8929 - val_loss: 0.2710 - val_accuracy: 0.8810\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2633 - accuracy: 0.9107 - val_loss: 0.2824 - val_accuracy: 0.8810\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2566 - accuracy: 0.9048 - val_loss: 0.2759 - val_accuracy: 0.8810\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 0s 314us/step - loss: 0.2543 - accuracy: 0.8929 - val_loss: 0.2693 - val_accuracy: 0.8571\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 0s 226us/step - loss: 0.2664 - accuracy: 0.9107 - val_loss: 0.2699 - val_accuracy: 0.8571\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 0s 226us/step - loss: 0.2738 - accuracy: 0.8929 - val_loss: 0.2693 - val_accuracy: 0.8810\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 0s 216us/step - loss: 0.2529 - accuracy: 0.9226 - val_loss: 0.2832 - val_accuracy: 0.8333\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2611 - accuracy: 0.9167 - val_loss: 0.2646 - val_accuracy: 0.8810\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 0s 240us/step - loss: 0.2546 - accuracy: 0.8869 - val_loss: 0.2681 - val_accuracy: 0.8810\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2535 - accuracy: 0.9048 - val_loss: 0.2653 - val_accuracy: 0.8571\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2513 - accuracy: 0.9167 - val_loss: 0.2655 - val_accuracy: 0.8810\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2507 - accuracy: 0.9048 - val_loss: 0.2669 - val_accuracy: 0.8810\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2489 - accuracy: 0.9048 - val_loss: 0.2641 - val_accuracy: 0.8571\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2486 - accuracy: 0.9167 - val_loss: 0.2623 - val_accuracy: 0.8810\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2463 - accuracy: 0.9167 - val_loss: 0.2608 - val_accuracy: 0.8810\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2465 - accuracy: 0.9167 - val_loss: 0.2610 - val_accuracy: 0.8810\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 0s 416us/step - loss: 0.2496 - accuracy: 0.9167 - val_loss: 0.2640 - val_accuracy: 0.8810\n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 286us/step - loss: 0.2432 - accuracy: 0.9107 - val_loss: 0.2620 - val_accuracy: 0.8810\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 0s 284us/step - loss: 0.2428 - accuracy: 0.9107 - val_loss: 0.2595 - val_accuracy: 0.8810\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2410 - accuracy: 0.9167 - val_loss: 0.2598 - val_accuracy: 0.8571\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 0s 282us/step - loss: 0.2417 - accuracy: 0.9107 - val_loss: 0.2577 - val_accuracy: 0.8810\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.96 - 0s 186us/step - loss: 0.2395 - accuracy: 0.9167 - val_loss: 0.2580 - val_accuracy: 0.8810\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2413 - accuracy: 0.9167 - val_loss: 0.2596 - val_accuracy: 0.9048\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - 0s 358us/step - loss: 0.2397 - accuracy: 0.9048 - val_loss: 0.2635 - val_accuracy: 0.9048\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 0s 309us/step - loss: 0.2421 - accuracy: 0.9226 - val_loss: 0.2624 - val_accuracy: 0.9048\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.2440 - accuracy: 0.8988 - val_loss: 0.2594 - val_accuracy: 0.9048\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 0s 264us/step - loss: 0.2486 - accuracy: 0.9107 - val_loss: 0.2717 - val_accuracy: 0.8571\n",
      "Epoch 314/1000\n",
      "168/168 [==============================] - 0s 240us/step - loss: 0.2517 - accuracy: 0.8988 - val_loss: 0.2590 - val_accuracy: 0.9048\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2367 - accuracy: 0.9107 - val_loss: 0.2700 - val_accuracy: 0.8571\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2467 - accuracy: 0.9167 - val_loss: 0.2519 - val_accuracy: 0.8571\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 0s 504us/step - loss: 0.2569 - accuracy: 0.8929 - val_loss: 0.2651 - val_accuracy: 0.8810\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2367 - accuracy: 0.9167 - val_loss: 0.2611 - val_accuracy: 0.8571\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2636 - accuracy: 0.8988 - val_loss: 0.2477 - val_accuracy: 0.8571\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 0s 287us/step - loss: 0.2585 - accuracy: 0.9107 - val_loss: 0.2745 - val_accuracy: 0.8810\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 0s 211us/step - loss: 0.2459 - accuracy: 0.8988 - val_loss: 0.2706 - val_accuracy: 0.8333\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 0s 269us/step - loss: 0.2479 - accuracy: 0.9048 - val_loss: 0.2624 - val_accuracy: 0.9048\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2531 - accuracy: 0.9107 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 0s 285us/step - loss: 0.2297 - accuracy: 0.9107 - val_loss: 0.2688 - val_accuracy: 0.8333\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2422 - accuracy: 0.9107 - val_loss: 0.2484 - val_accuracy: 0.9048\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2371 - accuracy: 0.9167 - val_loss: 0.2553 - val_accuracy: 0.8810\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 0s 360us/step - loss: 0.2367 - accuracy: 0.9048 - val_loss: 0.2483 - val_accuracy: 0.8571\n",
      "Epoch 328/1000\n",
      "168/168 [==============================] - 0s 303us/step - loss: 0.2284 - accuracy: 0.9226 - val_loss: 0.2548 - val_accuracy: 0.8810\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 0s 297us/step - loss: 0.2457 - accuracy: 0.8929 - val_loss: 0.2490 - val_accuracy: 0.9048\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.2371 - accuracy: 0.9048 - val_loss: 0.2505 - val_accuracy: 0.9048\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 0s 252us/step - loss: 0.2270 - accuracy: 0.9167 - val_loss: 0.2483 - val_accuracy: 0.8810\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2482 - accuracy: 0.9048 - val_loss: 0.2458 - val_accuracy: 0.8571\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2451 - accuracy: 0.9048 - val_loss: 0.2698 - val_accuracy: 0.8810\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2285 - accuracy: 0.9167 - val_loss: 0.2543 - val_accuracy: 0.8571\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2382 - accuracy: 0.9167 - val_loss: 0.2559 - val_accuracy: 0.9048\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2271 - accuracy: 0.9107 - val_loss: 0.2529 - val_accuracy: 0.9048\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2270 - accuracy: 0.9226 - val_loss: 0.2487 - val_accuracy: 0.9048\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 0s 317us/step - loss: 0.2247 - accuracy: 0.9167 - val_loss: 0.2498 - val_accuracy: 0.9048\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 0s 240us/step - loss: 0.2262 - accuracy: 0.9167 - val_loss: 0.2482 - val_accuracy: 0.9048\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2225 - accuracy: 0.9226 - val_loss: 0.2470 - val_accuracy: 0.9048\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2259 - accuracy: 0.9167 - val_loss: 0.2469 - val_accuracy: 0.9048\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2335 - accuracy: 0.9107 - val_loss: 0.2586 - val_accuracy: 0.9048\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2277 - accuracy: 0.9048 - val_loss: 0.2506 - val_accuracy: 0.8571\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2373 - accuracy: 0.9167 - val_loss: 0.2394 - val_accuracy: 0.8571\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 0s 334us/step - loss: 0.2376 - accuracy: 0.8810 - val_loss: 0.2569 - val_accuracy: 0.9048\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 0s 298us/step - loss: 0.2301 - accuracy: 0.9107 - val_loss: 0.2488 - val_accuracy: 0.8810\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.2239 - accuracy: 0.9226 - val_loss: 0.2546 - val_accuracy: 0.8810\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2275 - accuracy: 0.9048 - val_loss: 0.2527 - val_accuracy: 0.8810\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 0s 264us/step - loss: 0.2228 - accuracy: 0.9226 - val_loss: 0.2473 - val_accuracy: 0.9048\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2228 - accuracy: 0.9226 - val_loss: 0.2419 - val_accuracy: 0.8810\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2201 - accuracy: 0.9226 - val_loss: 0.2400 - val_accuracy: 0.8810\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2236 - accuracy: 0.9107 - val_loss: 0.2405 - val_accuracy: 0.9048\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2191 - accuracy: 0.9167 - val_loss: 0.2508 - val_accuracy: 0.8810\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2215 - accuracy: 0.9226 - val_loss: 0.2475 - val_accuracy: 0.9048\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2203 - accuracy: 0.9167 - val_loss: 0.2544 - val_accuracy: 0.8810\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 0s 384us/step - loss: 0.2253 - accuracy: 0.9107 - val_loss: 0.2480 - val_accuracy: 0.9048\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2194 - accuracy: 0.9226 - val_loss: 0.2411 - val_accuracy: 0.9048\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 0s 316us/step - loss: 0.2257 - accuracy: 0.9048 - val_loss: 0.2426 - val_accuracy: 0.8810\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.2189 - accuracy: 0.9226 - val_loss: 0.2475 - val_accuracy: 0.9048\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2209 - accuracy: 0.9226 - val_loss: 0.2428 - val_accuracy: 0.9048\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2191 - accuracy: 0.9167 - val_loss: 0.2419 - val_accuracy: 0.9048\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2202 - accuracy: 0.9167 - val_loss: 0.2433 - val_accuracy: 0.9048\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 0s 338us/step - loss: 0.2150 - accuracy: 0.9226 - val_loss: 0.2432 - val_accuracy: 0.9048\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 0s 303us/step - loss: 0.2138 - accuracy: 0.9286 - val_loss: 0.2409 - val_accuracy: 0.9048\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 0s 299us/step - loss: 0.2153 - accuracy: 0.9167 - val_loss: 0.2402 - val_accuracy: 0.9048\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 0s 291us/step - loss: 0.2137 - accuracy: 0.9167 - val_loss: 0.2393 - val_accuracy: 0.9048\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.2250 - accuracy: 0.9048 - val_loss: 0.2448 - val_accuracy: 0.9048\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 0s 303us/step - loss: 0.2172 - accuracy: 0.9107 - val_loss: 0.2368 - val_accuracy: 0.8810\n",
      "Epoch 369/1000\n",
      "168/168 [==============================] - 0s 315us/step - loss: 0.2150 - accuracy: 0.9226 - val_loss: 0.2385 - val_accuracy: 0.8810\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 0s 291us/step - loss: 0.2117 - accuracy: 0.9226 - val_loss: 0.2427 - val_accuracy: 0.9048\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2136 - accuracy: 0.9107 - val_loss: 0.2457 - val_accuracy: 0.9048\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 0s 315us/step - loss: 0.2143 - accuracy: 0.9226 - val_loss: 0.2383 - val_accuracy: 0.9048\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2135 - accuracy: 0.9226 - val_loss: 0.2370 - val_accuracy: 0.8810\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 0s 312us/step - loss: 0.2107 - accuracy: 0.9286 - val_loss: 0.2382 - val_accuracy: 0.9048\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 0s 309us/step - loss: 0.2141 - accuracy: 0.9167 - val_loss: 0.2425 - val_accuracy: 0.9048\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2287 - accuracy: 0.8988 - val_loss: 0.2472 - val_accuracy: 0.8810\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 0s 306us/step - loss: 0.2152 - accuracy: 0.9226 - val_loss: 0.2397 - val_accuracy: 0.9048\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2150 - accuracy: 0.9167 - val_loss: 0.2442 - val_accuracy: 0.8810\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2106 - accuracy: 0.9167 - val_loss: 0.2371 - val_accuracy: 0.9048\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 0s 413us/step - loss: 0.2095 - accuracy: 0.9226 - val_loss: 0.2348 - val_accuracy: 0.9048\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 0s 227us/step - loss: 0.2103 - accuracy: 0.9226 - val_loss: 0.2364 - val_accuracy: 0.8810\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 0s 222us/step - loss: 0.2095 - accuracy: 0.9226 - val_loss: 0.2409 - val_accuracy: 0.9048\n",
      "Epoch 383/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2098 - accuracy: 0.9226 - val_loss: 0.2336 - val_accuracy: 0.8810\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2131 - accuracy: 0.9167 - val_loss: 0.2323 - val_accuracy: 0.8810\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2093 - accuracy: 0.9226 - val_loss: 0.2374 - val_accuracy: 0.9048\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2125 - accuracy: 0.9107 - val_loss: 0.2375 - val_accuracy: 0.9048\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2079 - accuracy: 0.9286 - val_loss: 0.2344 - val_accuracy: 0.9048\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2078 - accuracy: 0.9226 - val_loss: 0.2351 - val_accuracy: 0.9048\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2093 - accuracy: 0.9167 - val_loss: 0.2474 - val_accuracy: 0.8810\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2113 - accuracy: 0.9107 - val_loss: 0.2504 - val_accuracy: 0.8810\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 0s 348us/step - loss: 0.2114 - accuracy: 0.9167 - val_loss: 0.2510 - val_accuracy: 0.9048\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2111 - accuracy: 0.9226 - val_loss: 0.2416 - val_accuracy: 0.8810\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.2089 - accuracy: 0.9107 - val_loss: 0.2404 - val_accuracy: 0.9048\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2135 - accuracy: 0.9226 - val_loss: 0.2382 - val_accuracy: 0.8810\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2090 - accuracy: 0.9226 - val_loss: 0.2352 - val_accuracy: 0.9048\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2068 - accuracy: 0.9226 - val_loss: 0.2373 - val_accuracy: 0.9048\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 0s 327us/step - loss: 0.2083 - accuracy: 0.9286 - val_loss: 0.2413 - val_accuracy: 0.8810\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 0s 304us/step - loss: 0.2070 - accuracy: 0.9167 - val_loss: 0.2398 - val_accuracy: 0.8810\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 0s 211us/step - loss: 0.2057 - accuracy: 0.9226 - val_loss: 0.2397 - val_accuracy: 0.9048\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 0s 216us/step - loss: 0.2183 - accuracy: 0.9107 - val_loss: 0.2375 - val_accuracy: 0.9048\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2133 - accuracy: 0.9107 - val_loss: 0.2537 - val_accuracy: 0.8810\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2143 - accuracy: 0.9048 - val_loss: 0.2392 - val_accuracy: 0.9048\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2080 - accuracy: 0.9167 - val_loss: 0.2416 - val_accuracy: 0.8810\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2059 - accuracy: 0.9167 - val_loss: 0.2355 - val_accuracy: 0.9048\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2074 - accuracy: 0.9226 - val_loss: 0.2324 - val_accuracy: 0.9048\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2194 - accuracy: 0.9107 - val_loss: 0.2288 - val_accuracy: 0.8810\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2073 - accuracy: 0.9107 - val_loss: 0.2408 - val_accuracy: 0.8810\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 0s 385us/step - loss: 0.2072 - accuracy: 0.9167 - val_loss: 0.2300 - val_accuracy: 0.8810\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 0s 258us/step - loss: 0.2060 - accuracy: 0.9226 - val_loss: 0.2400 - val_accuracy: 0.9048\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 0s 312us/step - loss: 0.2042 - accuracy: 0.9107 - val_loss: 0.2473 - val_accuracy: 0.8810\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2064 - accuracy: 0.9107 - val_loss: 0.2372 - val_accuracy: 0.8810\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2010 - accuracy: 0.9167 - val_loss: 0.2385 - val_accuracy: 0.9048\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2018 - accuracy: 0.9226 - val_loss: 0.2352 - val_accuracy: 0.9048\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 225us/step - loss: 0.2090 - accuracy: 0.9107 - val_loss: 0.2442 - val_accuracy: 0.8571\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 0s 335us/step - loss: 0.2108 - accuracy: 0.9048 - val_loss: 0.2308 - val_accuracy: 0.8810\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 0s 333us/step - loss: 0.2013 - accuracy: 0.9286 - val_loss: 0.2416 - val_accuracy: 0.8810\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 0s 309us/step - loss: 0.2010 - accuracy: 0.9167 - val_loss: 0.2359 - val_accuracy: 0.8810\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 0s 247us/step - loss: 0.2117 - accuracy: 0.9107 - val_loss: 0.2302 - val_accuracy: 0.9048\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 0s 266us/step - loss: 0.2195 - accuracy: 0.9107 - val_loss: 0.2575 - val_accuracy: 0.8571\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.90 - 0s 186us/step - loss: 0.2053 - accuracy: 0.9107 - val_loss: 0.2452 - val_accuracy: 0.8810\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 0s 318us/step - loss: 0.2092 - accuracy: 0.9048 - val_loss: 0.2428 - val_accuracy: 0.8810\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2015 - accuracy: 0.9226 - val_loss: 0.2325 - val_accuracy: 0.8810\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.1996 - accuracy: 0.9286 - val_loss: 0.2305 - val_accuracy: 0.8810\n",
      "Epoch 424/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1983 - accuracy: 0.9345 - val_loss: 0.2310 - val_accuracy: 0.9048\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2055 - accuracy: 0.9226 - val_loss: 0.2305 - val_accuracy: 0.9048\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 0s 321us/step - loss: 0.2018 - accuracy: 0.9286 - val_loss: 0.2373 - val_accuracy: 0.8810\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 0s 264us/step - loss: 0.1933 - accuracy: 0.9286 - val_loss: 0.2407 - val_accuracy: 0.8810\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 0s 264us/step - loss: 0.2161 - accuracy: 0.9048 - val_loss: 0.2422 - val_accuracy: 0.8810\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2002 - accuracy: 0.9167 - val_loss: 0.2472 - val_accuracy: 0.8810\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.87 - 0s 225us/step - loss: 0.2037 - accuracy: 0.9167 - val_loss: 0.2347 - val_accuracy: 0.8810\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1985 - accuracy: 0.9226 - val_loss: 0.2348 - val_accuracy: 0.8810\n",
      "Train on 168 samples, validate on 42 samples\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 2s 10ms/step - loss: 1.3937 - accuracy: 0.3512 - val_loss: 1.3788 - val_accuracy: 0.2619\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.3114 - accuracy: 0.3452 - val_loss: 1.3261 - val_accuracy: 0.3095\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.2861 - accuracy: 0.3750 - val_loss: 1.3013 - val_accuracy: 0.3095\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.2553 - accuracy: 0.3988 - val_loss: 1.2677 - val_accuracy: 0.3333\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.2199 - accuracy: 0.3690 - val_loss: 1.2351 - val_accuracy: 0.3095\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.1832 - accuracy: 0.3571 - val_loss: 1.2031 - val_accuracy: 0.2381\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 0s 320us/step - loss: 1.1563 - accuracy: 0.3274 - val_loss: 1.1730 - val_accuracy: 0.2381\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.1295 - accuracy: 0.3452 - val_loss: 1.1561 - val_accuracy: 0.2619\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.1129 - accuracy: 0.3512 - val_loss: 1.1453 - val_accuracy: 0.2619\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 1.0916 - accuracy: 0.3512 - val_loss: 1.1134 - val_accuracy: 0.2381\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0671 - accuracy: 0.3274 - val_loss: 1.0759 - val_accuracy: 0.2619\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0508 - accuracy: 0.3452 - val_loss: 1.0567 - val_accuracy: 0.3333\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0346 - accuracy: 0.4345 - val_loss: 1.0402 - val_accuracy: 0.4048\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 0s 324us/step - loss: 1.0167 - accuracy: 0.5119 - val_loss: 1.0169 - val_accuracy: 0.5714\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 1.0016 - accuracy: 0.5476 - val_loss: 0.9993 - val_accuracy: 0.5952\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9888 - accuracy: 0.5357 - val_loss: 0.9940 - val_accuracy: 0.5476\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9768 - accuracy: 0.5476 - val_loss: 0.9820 - val_accuracy: 0.5714\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9622 - accuracy: 0.5536 - val_loss: 0.9542 - val_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.9487 - accuracy: 0.5655 - val_loss: 0.9363 - val_accuracy: 0.6905\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9418 - accuracy: 0.5774 - val_loss: 0.9195 - val_accuracy: 0.6190\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 0s 414us/step - loss: 0.9291 - accuracy: 0.5833 - val_loss: 0.9145 - val_accuracy: 0.6429\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9172 - accuracy: 0.6012 - val_loss: 0.9051 - val_accuracy: 0.6905\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.9059 - accuracy: 0.5893 - val_loss: 0.8860 - val_accuracy: 0.7143\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8990 - accuracy: 0.5893 - val_loss: 0.8700 - val_accuracy: 0.6905\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 0s 308us/step - loss: 0.8879 - accuracy: 0.5952 - val_loss: 0.8652 - val_accuracy: 0.6190\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8853 - accuracy: 0.5893 - val_loss: 0.8511 - val_accuracy: 0.6429\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8772 - accuracy: 0.5893 - val_loss: 0.8484 - val_accuracy: 0.6429\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8674 - accuracy: 0.6071 - val_loss: 0.8353 - val_accuracy: 0.6905\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8682 - accuracy: 0.5952 - val_loss: 0.8293 - val_accuracy: 0.7619\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.8608 - accuracy: 0.5774 - val_loss: 0.8285 - val_accuracy: 0.7381\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8563 - accuracy: 0.5774 - val_loss: 0.8193 - val_accuracy: 0.6667\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 0s 399us/step - loss: 0.8555 - accuracy: 0.6071 - val_loss: 0.8086 - val_accuracy: 0.7143\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 0s 262us/step - loss: 0.8481 - accuracy: 0.6131 - val_loss: 0.8340 - val_accuracy: 0.6905\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 0s 199us/step - loss: 0.8439 - accuracy: 0.6012 - val_loss: 0.8094 - val_accuracy: 0.6905\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8372 - accuracy: 0.6012 - val_loss: 0.8039 - val_accuracy: 0.6905\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8349 - accuracy: 0.6012 - val_loss: 0.7979 - val_accuracy: 0.7143\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8340 - accuracy: 0.5893 - val_loss: 0.7936 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8261 - accuracy: 0.6012 - val_loss: 0.8052 - val_accuracy: 0.7143\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.8252 - accuracy: 0.6012 - val_loss: 0.8031 - val_accuracy: 0.6429\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8226 - accuracy: 0.5952 - val_loss: 0.7929 - val_accuracy: 0.6429\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8348 - accuracy: 0.6071 - val_loss: 0.7837 - val_accuracy: 0.6667\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 0s 377us/step - loss: 0.8227 - accuracy: 0.5952 - val_loss: 0.8171 - val_accuracy: 0.6667\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8316 - accuracy: 0.6071 - val_loss: 0.8182 - val_accuracy: 0.6905\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 0s 316us/step - loss: 0.8232 - accuracy: 0.6190 - val_loss: 0.7765 - val_accuracy: 0.7143\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.8171 - accuracy: 0.6012 - val_loss: 0.7761 - val_accuracy: 0.7381\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8155 - accuracy: 0.5833 - val_loss: 0.7680 - val_accuracy: 0.7143\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8092 - accuracy: 0.5952 - val_loss: 0.7764 - val_accuracy: 0.7143\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8156 - accuracy: 0.6012 - val_loss: 0.7998 - val_accuracy: 0.6667\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 0s 449us/step - loss: 0.8069 - accuracy: 0.6071 - val_loss: 0.7682 - val_accuracy: 0.6667\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 0s 297us/step - loss: 0.8092 - accuracy: 0.6190 - val_loss: 0.7625 - val_accuracy: 0.7143\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 0s 198us/step - loss: 0.8035 - accuracy: 0.6131 - val_loss: 0.7763 - val_accuracy: 0.6905\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8058 - accuracy: 0.6131 - val_loss: 0.7870 - val_accuracy: 0.6667\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7960 - accuracy: 0.6310 - val_loss: 0.7589 - val_accuracy: 0.6905\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.8021 - accuracy: 0.6012 - val_loss: 0.7529 - val_accuracy: 0.7143\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.8106 - accuracy: 0.5774 - val_loss: 0.7515 - val_accuracy: 0.7143\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7995 - accuracy: 0.5893 - val_loss: 0.7797 - val_accuracy: 0.7381\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7968 - accuracy: 0.6369 - val_loss: 0.7616 - val_accuracy: 0.7143\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7947 - accuracy: 0.6012 - val_loss: 0.7518 - val_accuracy: 0.7143\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7922 - accuracy: 0.6310 - val_loss: 0.7680 - val_accuracy: 0.7143\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 0s 278us/step - loss: 0.7920 - accuracy: 0.6250 - val_loss: 0.7628 - val_accuracy: 0.7143\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7920 - accuracy: 0.6250 - val_loss: 0.7473 - val_accuracy: 0.7381\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7888 - accuracy: 0.5952 - val_loss: 0.7422 - val_accuracy: 0.7143\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7914 - accuracy: 0.5774 - val_loss: 0.7478 - val_accuracy: 0.7143\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7838 - accuracy: 0.6131 - val_loss: 0.7629 - val_accuracy: 0.6667\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7873 - accuracy: 0.6012 - val_loss: 0.7526 - val_accuracy: 0.7381\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 0s 301us/step - loss: 0.7829 - accuracy: 0.6310 - val_loss: 0.7424 - val_accuracy: 0.6905\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 0s 351us/step - loss: 0.7887 - accuracy: 0.6429 - val_loss: 0.7397 - val_accuracy: 0.7143\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 0s 289us/step - loss: 0.7849 - accuracy: 0.6071 - val_loss: 0.7528 - val_accuracy: 0.7381\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.7779 - accuracy: 0.6310 - val_loss: 0.7393 - val_accuracy: 0.6905\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 0s 198us/step - loss: 0.7855 - accuracy: 0.6369 - val_loss: 0.7357 - val_accuracy: 0.7143\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7759 - accuracy: 0.6369 - val_loss: 0.7538 - val_accuracy: 0.7381\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7820 - accuracy: 0.6429 - val_loss: 0.7534 - val_accuracy: 0.7619\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7762 - accuracy: 0.6429 - val_loss: 0.7389 - val_accuracy: 0.7143\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7756 - accuracy: 0.6369 - val_loss: 0.7310 - val_accuracy: 0.7381\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7709 - accuracy: 0.6369 - val_loss: 0.7492 - val_accuracy: 0.7143\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7755 - accuracy: 0.6190 - val_loss: 0.7436 - val_accuracy: 0.7143\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7696 - accuracy: 0.6250 - val_loss: 0.7300 - val_accuracy: 0.7381\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 0s 324us/step - loss: 0.7672 - accuracy: 0.6250 - val_loss: 0.7327 - val_accuracy: 0.7381\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 0s 307us/step - loss: 0.7664 - accuracy: 0.6250 - val_loss: 0.7276 - val_accuracy: 0.7381\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7655 - accuracy: 0.6190 - val_loss: 0.7343 - val_accuracy: 0.7619\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7645 - accuracy: 0.6369 - val_loss: 0.7366 - val_accuracy: 0.7381\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7657 - accuracy: 0.6131 - val_loss: 0.7378 - val_accuracy: 0.6667\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7655 - accuracy: 0.6310 - val_loss: 0.7387 - val_accuracy: 0.7143\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 0s 397us/step - loss: 0.7618 - accuracy: 0.6012 - val_loss: 0.7353 - val_accuracy: 0.7143\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 0s 381us/step - loss: 0.7605 - accuracy: 0.6429 - val_loss: 0.7263 - val_accuracy: 0.7381\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 0s 351us/step - loss: 0.7613 - accuracy: 0.6548 - val_loss: 0.7194 - val_accuracy: 0.7381\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 0s 232us/step - loss: 0.7683 - accuracy: 0.6429 - val_loss: 0.7211 - val_accuracy: 0.7381\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 0s 180us/step - loss: 0.7568 - accuracy: 0.6369 - val_loss: 0.7238 - val_accuracy: 0.7381\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7552 - accuracy: 0.6607 - val_loss: 0.7258 - val_accuracy: 0.7381\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7589 - accuracy: 0.6131 - val_loss: 0.7284 - val_accuracy: 0.7143\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.7552 - accuracy: 0.6369 - val_loss: 0.7193 - val_accuracy: 0.7381\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.7556 - accuracy: 0.6726 - val_loss: 0.7177 - val_accuracy: 0.7381\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7538 - accuracy: 0.6488 - val_loss: 0.7236 - val_accuracy: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000\n",
      "168/168 [==============================] - 0s 302us/step - loss: 0.7506 - accuracy: 0.6488 - val_loss: 0.7307 - val_accuracy: 0.7381\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7476 - accuracy: 0.6369 - val_loss: 0.7134 - val_accuracy: 0.7381\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7494 - accuracy: 0.6488 - val_loss: 0.7068 - val_accuracy: 0.7381\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7483 - accuracy: 0.6548 - val_loss: 0.7114 - val_accuracy: 0.7619\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7416 - accuracy: 0.6548 - val_loss: 0.7042 - val_accuracy: 0.7381\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7418 - accuracy: 0.6667 - val_loss: 0.7058 - val_accuracy: 0.7619\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 0s 343us/step - loss: 0.7411 - accuracy: 0.6310 - val_loss: 0.7172 - val_accuracy: 0.7381\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7426 - accuracy: 0.6369 - val_loss: 0.7056 - val_accuracy: 0.7619\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7509 - accuracy: 0.6726 - val_loss: 0.7028 - val_accuracy: 0.7619\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7462 - accuracy: 0.6131 - val_loss: 0.6928 - val_accuracy: 0.7381\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7425 - accuracy: 0.6310 - val_loss: 0.7011 - val_accuracy: 0.7619\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7372 - accuracy: 0.6607 - val_loss: 0.7112 - val_accuracy: 0.7619\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7352 - accuracy: 0.6607 - val_loss: 0.6972 - val_accuracy: 0.7857\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7347 - accuracy: 0.6845 - val_loss: 0.6984 - val_accuracy: 0.7857\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7341 - accuracy: 0.6607 - val_loss: 0.6921 - val_accuracy: 0.7619\n",
      "Epoch 109/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7296 - accuracy: 0.6548 - val_loss: 0.7026 - val_accuracy: 0.7619\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 0s 212us/step - loss: 0.7323 - accuracy: 0.6786 - val_loss: 0.6931 - val_accuracy: 0.7619\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 0s 141us/step - loss: 0.7279 - accuracy: 0.6845 - val_loss: 0.6903 - val_accuracy: 0.7619\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7290 - accuracy: 0.6905 - val_loss: 0.6913 - val_accuracy: 0.7857\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 0s 219us/step - loss: 0.7223 - accuracy: 0.6786 - val_loss: 0.6886 - val_accuracy: 0.7857\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7248 - accuracy: 0.6548 - val_loss: 0.6797 - val_accuracy: 0.7619\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7233 - accuracy: 0.6845 - val_loss: 0.6937 - val_accuracy: 0.7619\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7245 - accuracy: 0.6726 - val_loss: 0.6861 - val_accuracy: 0.7381\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7203 - accuracy: 0.7024 - val_loss: 0.6782 - val_accuracy: 0.7619\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7153 - accuracy: 0.6905 - val_loss: 0.6860 - val_accuracy: 0.7619\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 0s 374us/step - loss: 0.7120 - accuracy: 0.7143 - val_loss: 0.6747 - val_accuracy: 0.7857\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 0s 177us/step - loss: 0.7122 - accuracy: 0.7083 - val_loss: 0.6908 - val_accuracy: 0.7619\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 0s 216us/step - loss: 0.7078 - accuracy: 0.7083 - val_loss: 0.6723 - val_accuracy: 0.7857\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7103 - accuracy: 0.7202 - val_loss: 0.6694 - val_accuracy: 0.7619\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7095 - accuracy: 0.7024 - val_loss: 0.6798 - val_accuracy: 0.7857\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7002 - accuracy: 0.7262 - val_loss: 0.6664 - val_accuracy: 0.7619\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7175 - accuracy: 0.6964 - val_loss: 0.6704 - val_accuracy: 0.7381\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.7006 - accuracy: 0.7143 - val_loss: 0.6857 - val_accuracy: 0.7619\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.7012 - accuracy: 0.7202 - val_loss: 0.6594 - val_accuracy: 0.7857\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7029 - accuracy: 0.6964 - val_loss: 0.6605 - val_accuracy: 0.7857\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6922 - accuracy: 0.7262 - val_loss: 0.6871 - val_accuracy: 0.7619\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.7024 - accuracy: 0.6905 - val_loss: 0.6654 - val_accuracy: 0.7619\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6935 - accuracy: 0.7321 - val_loss: 0.6675 - val_accuracy: 0.7857\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 0s 247us/step - loss: 0.6873 - accuracy: 0.7262 - val_loss: 0.6535 - val_accuracy: 0.7857\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6898 - accuracy: 0.7262 - val_loss: 0.6586 - val_accuracy: 0.7619\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6926 - accuracy: 0.7143 - val_loss: 0.6701 - val_accuracy: 0.7619\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6987 - accuracy: 0.6845 - val_loss: 0.6822 - val_accuracy: 0.7857\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6889 - accuracy: 0.7440 - val_loss: 0.6417 - val_accuracy: 0.7619\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6916 - accuracy: 0.6905 - val_loss: 0.6417 - val_accuracy: 0.7857\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6827 - accuracy: 0.7083 - val_loss: 0.6473 - val_accuracy: 0.7857\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6821 - accuracy: 0.7262 - val_loss: 0.6371 - val_accuracy: 0.7857\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 0s 375us/step - loss: 0.6810 - accuracy: 0.6905 - val_loss: 0.6434 - val_accuracy: 0.7857\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 0s 233us/step - loss: 0.6794 - accuracy: 0.7440 - val_loss: 0.6525 - val_accuracy: 0.7857\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6691 - accuracy: 0.7143 - val_loss: 0.6473 - val_accuracy: 0.7857\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6715 - accuracy: 0.7143 - val_loss: 0.6328 - val_accuracy: 0.7857\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6706 - accuracy: 0.7500 - val_loss: 0.6339 - val_accuracy: 0.7857\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6661 - accuracy: 0.7440 - val_loss: 0.6448 - val_accuracy: 0.7857\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6649 - accuracy: 0.7381 - val_loss: 0.6359 - val_accuracy: 0.7857\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6610 - accuracy: 0.7560 - val_loss: 0.6272 - val_accuracy: 0.7857\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6588 - accuracy: 0.7381 - val_loss: 0.6259 - val_accuracy: 0.7857\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.6597 - accuracy: 0.7500 - val_loss: 0.6184 - val_accuracy: 0.7857\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.6562 - accuracy: 0.7381 - val_loss: 0.6365 - val_accuracy: 0.8095\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 0s 347us/step - loss: 0.6630 - accuracy: 0.7321 - val_loss: 0.6372 - val_accuracy: 0.7857\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6515 - accuracy: 0.7738 - val_loss: 0.6170 - val_accuracy: 0.7857\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 0s 232us/step - loss: 0.6504 - accuracy: 0.7619 - val_loss: 0.6186 - val_accuracy: 0.7857\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6506 - accuracy: 0.7381 - val_loss: 0.6132 - val_accuracy: 0.7857\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6483 - accuracy: 0.7560 - val_loss: 0.6172 - val_accuracy: 0.8095\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6503 - accuracy: 0.7798 - val_loss: 0.6123 - val_accuracy: 0.8095\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6505 - accuracy: 0.7679 - val_loss: 0.6389 - val_accuracy: 0.8095\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 0s 367us/step - loss: 0.6404 - accuracy: 0.7738 - val_loss: 0.6061 - val_accuracy: 0.8095\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.6420 - accuracy: 0.7679 - val_loss: 0.6061 - val_accuracy: 0.7857\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 0s 259us/step - loss: 0.6333 - accuracy: 0.7500 - val_loss: 0.6064 - val_accuracy: 0.8095\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6375 - accuracy: 0.7500 - val_loss: 0.6051 - val_accuracy: 0.8095\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6324 - accuracy: 0.7679 - val_loss: 0.6104 - val_accuracy: 0.7857\n",
      "Epoch 163/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6309 - accuracy: 0.7679 - val_loss: 0.6083 - val_accuracy: 0.8333\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6405 - accuracy: 0.7560 - val_loss: 0.5935 - val_accuracy: 0.8333\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6403 - accuracy: 0.7857 - val_loss: 0.6027 - val_accuracy: 0.7857\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6198 - accuracy: 0.8095 - val_loss: 0.6182 - val_accuracy: 0.8571\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6405 - accuracy: 0.7321 - val_loss: 0.5905 - val_accuracy: 0.8333\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6380 - accuracy: 0.7560 - val_loss: 0.5951 - val_accuracy: 0.7857\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 0s 296us/step - loss: 0.6214 - accuracy: 0.7857 - val_loss: 0.6166 - val_accuracy: 0.8095\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6234 - accuracy: 0.7738 - val_loss: 0.5920 - val_accuracy: 0.7857\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6203 - accuracy: 0.7679 - val_loss: 0.5998 - val_accuracy: 0.8333\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6113 - accuracy: 0.7738 - val_loss: 0.5777 - val_accuracy: 0.8095\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6215 - accuracy: 0.7857 - val_loss: 0.5704 - val_accuracy: 0.8333\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6041 - accuracy: 0.7976 - val_loss: 0.6003 - val_accuracy: 0.8333\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.6100 - accuracy: 0.7679 - val_loss: 0.5732 - val_accuracy: 0.8095\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 0s 333us/step - loss: 0.6200 - accuracy: 0.7976 - val_loss: 0.5651 - val_accuracy: 0.8095\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 0s 291us/step - loss: 0.5958 - accuracy: 0.7976 - val_loss: 0.5793 - val_accuracy: 0.8333\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 0s 262us/step - loss: 0.6009 - accuracy: 0.7798 - val_loss: 0.5882 - val_accuracy: 0.8333\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 0s 260us/step - loss: 0.5965 - accuracy: 0.7798 - val_loss: 0.5706 - val_accuracy: 0.8333\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5874 - accuracy: 0.7976 - val_loss: 0.5609 - val_accuracy: 0.8571\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.6034 - accuracy: 0.7560 - val_loss: 0.5534 - val_accuracy: 0.8333\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5902 - accuracy: 0.8036 - val_loss: 0.5675 - val_accuracy: 0.8333\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5944 - accuracy: 0.8036 - val_loss: 0.5559 - val_accuracy: 0.8333\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5797 - accuracy: 0.7917 - val_loss: 0.5590 - val_accuracy: 0.8571\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5794 - accuracy: 0.8214 - val_loss: 0.5489 - val_accuracy: 0.8095\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5858 - accuracy: 0.8155 - val_loss: 0.5616 - val_accuracy: 0.8333\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 0s 363us/step - loss: 0.5903 - accuracy: 0.7976 - val_loss: 0.5769 - val_accuracy: 0.8333\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 0s 246us/step - loss: 0.5830 - accuracy: 0.7917 - val_loss: 0.5403 - val_accuracy: 0.8095\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 0s 337us/step - loss: 0.6016 - accuracy: 0.8155 - val_loss: 0.5461 - val_accuracy: 0.8333\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5768 - accuracy: 0.8155 - val_loss: 0.5736 - val_accuracy: 0.8571\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5671 - accuracy: 0.8095 - val_loss: 0.5447 - val_accuracy: 0.8333\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5632 - accuracy: 0.8155 - val_loss: 0.5312 - val_accuracy: 0.8571\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5595 - accuracy: 0.8512 - val_loss: 0.5407 - val_accuracy: 0.8333\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 0s 374us/step - loss: 0.5536 - accuracy: 0.8333 - val_loss: 0.5526 - val_accuracy: 0.8333\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 0s 298us/step - loss: 0.5546 - accuracy: 0.8095 - val_loss: 0.5318 - val_accuracy: 0.8333\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.5516 - accuracy: 0.8512 - val_loss: 0.5227 - val_accuracy: 0.8571\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 0s 345us/step - loss: 0.5486 - accuracy: 0.8393 - val_loss: 0.5303 - val_accuracy: 0.8571\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5428 - accuracy: 0.8274 - val_loss: 0.5388 - val_accuracy: 0.8571\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.5558 - accuracy: 0.8274 - val_loss: 0.5251 - val_accuracy: 0.8571\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5428 - accuracy: 0.8333 - val_loss: 0.5312 - val_accuracy: 0.8571\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5429 - accuracy: 0.8214 - val_loss: 0.5129 - val_accuracy: 0.8571\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5584 - accuracy: 0.8214 - val_loss: 0.5316 - val_accuracy: 0.8571\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5531 - accuracy: 0.8095 - val_loss: 0.5355 - val_accuracy: 0.8810\n",
      "Epoch 204/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 285us/step - loss: 0.5448 - accuracy: 0.8571 - val_loss: 0.5199 - val_accuracy: 0.8571\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 0s 317us/step - loss: 0.5267 - accuracy: 0.8393 - val_loss: 0.5278 - val_accuracy: 0.8571\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5339 - accuracy: 0.8512 - val_loss: 0.4999 - val_accuracy: 0.8571\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.5253 - accuracy: 0.8452 - val_loss: 0.5062 - val_accuracy: 0.8571\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5251 - accuracy: 0.8393 - val_loss: 0.5131 - val_accuracy: 0.8810\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5191 - accuracy: 0.8631 - val_loss: 0.4971 - val_accuracy: 0.8571\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5203 - accuracy: 0.8512 - val_loss: 0.5016 - val_accuracy: 0.8810\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 0s 354us/step - loss: 0.5129 - accuracy: 0.8750 - val_loss: 0.4985 - val_accuracy: 0.8571\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.5156 - accuracy: 0.8452 - val_loss: 0.5301 - val_accuracy: 0.8571\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.5121 - accuracy: 0.8333 - val_loss: 0.4923 - val_accuracy: 0.8571\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 0s 294us/step - loss: 0.5046 - accuracy: 0.8631 - val_loss: 0.4777 - val_accuracy: 0.8333\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 0s 262us/step - loss: 0.5052 - accuracy: 0.8333 - val_loss: 0.4972 - val_accuracy: 0.8571\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 0s 208us/step - loss: 0.5164 - accuracy: 0.7976 - val_loss: 0.5276 - val_accuracy: 0.8571\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.5095 - accuracy: 0.8333 - val_loss: 0.4822 - val_accuracy: 0.8571\n",
      "Epoch 218/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4992 - accuracy: 0.8452 - val_loss: 0.4780 - val_accuracy: 0.8571\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4943 - accuracy: 0.8631 - val_loss: 0.5079 - val_accuracy: 0.8810\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4941 - accuracy: 0.8631 - val_loss: 0.4768 - val_accuracy: 0.8810\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4838 - accuracy: 0.8810 - val_loss: 0.4828 - val_accuracy: 0.8810\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5081 - accuracy: 0.8155 - val_loss: 0.4870 - val_accuracy: 0.8810\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 0s 338us/step - loss: 0.4969 - accuracy: 0.8274 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5343 - accuracy: 0.8214 - val_loss: 0.4687 - val_accuracy: 0.8810\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 0s 227us/step - loss: 0.5031 - accuracy: 0.8571 - val_loss: 0.5452 - val_accuracy: 0.8810\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4900 - accuracy: 0.8750 - val_loss: 0.4725 - val_accuracy: 0.8571\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4688 - accuracy: 0.8750 - val_loss: 0.4738 - val_accuracy: 0.8810\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4669 - accuracy: 0.8810 - val_loss: 0.4761 - val_accuracy: 0.8571\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5004 - accuracy: 0.8214 - val_loss: 0.4874 - val_accuracy: 0.8810\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 0s 396us/step - loss: 0.4729 - accuracy: 0.8452 - val_loss: 0.4525 - val_accuracy: 0.8571\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4612 - accuracy: 0.8571 - val_loss: 0.4621 - val_accuracy: 0.8810\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4686 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8810\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4698 - accuracy: 0.8750 - val_loss: 0.4556 - val_accuracy: 0.8810\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4596 - accuracy: 0.8988 - val_loss: 0.5014 - val_accuracy: 0.9048\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4645 - accuracy: 0.8571 - val_loss: 0.4456 - val_accuracy: 0.8810\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4443 - accuracy: 0.8869 - val_loss: 0.4539 - val_accuracy: 0.8571\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4483 - accuracy: 0.8988 - val_loss: 0.4500 - val_accuracy: 0.8810\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4599 - accuracy: 0.8690 - val_loss: 0.4393 - val_accuracy: 0.8810\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4452 - accuracy: 0.8810 - val_loss: 0.4323 - val_accuracy: 0.8810\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4393 - accuracy: 0.8810 - val_loss: 0.4577 - val_accuracy: 0.8810\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 0s 383us/step - loss: 0.4370 - accuracy: 0.8988 - val_loss: 0.4476 - val_accuracy: 0.8810\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4332 - accuracy: 0.9226 - val_loss: 0.4440 - val_accuracy: 0.8810\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.5013 - accuracy: 0.7798 - val_loss: 0.4424 - val_accuracy: 0.8810\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4677 - accuracy: 0.8155 - val_loss: 0.4260 - val_accuracy: 0.8810\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4429 - accuracy: 0.8631 - val_loss: 0.4559 - val_accuracy: 0.8571\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4372 - accuracy: 0.8690 - val_loss: 0.4391 - val_accuracy: 0.8810\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4539 - accuracy: 0.8452 - val_loss: 0.4277 - val_accuracy: 0.8571\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 0s 341us/step - loss: 0.4653 - accuracy: 0.8214 - val_loss: 0.4516 - val_accuracy: 0.8810\n",
      "Epoch 249/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4994 - accuracy: 0.8512 - val_loss: 0.4819 - val_accuracy: 0.8810\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 0s 222us/step - loss: 0.4554 - accuracy: 0.8690 - val_loss: 0.4109 - val_accuracy: 0.8571\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4297 - accuracy: 0.8929 - val_loss: 0.4635 - val_accuracy: 0.8810\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4198 - accuracy: 0.9167 - val_loss: 0.4219 - val_accuracy: 0.8810\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.4176 - accuracy: 0.9048 - val_loss: 0.4265 - val_accuracy: 0.8810\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.4111 - accuracy: 0.9107 - val_loss: 0.4125 - val_accuracy: 0.8810\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 0s 381us/step - loss: 0.4175 - accuracy: 0.8810 - val_loss: 0.4036 - val_accuracy: 0.8810\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 0s 285us/step - loss: 0.4236 - accuracy: 0.8631 - val_loss: 0.4049 - val_accuracy: 0.8810\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4115 - accuracy: 0.8929 - val_loss: 0.4453 - val_accuracy: 0.8810\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4021 - accuracy: 0.9107 - val_loss: 0.4365 - val_accuracy: 0.9048\n",
      "Epoch 259/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 236us/step - loss: 0.4355 - accuracy: 0.8631 - val_loss: 0.3920 - val_accuracy: 0.8571\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 0s 304us/step - loss: 0.4069 - accuracy: 0.9048 - val_loss: 0.4035 - val_accuracy: 0.8810\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4007 - accuracy: 0.9167 - val_loss: 0.4556 - val_accuracy: 0.8810\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4016 - accuracy: 0.9226 - val_loss: 0.3928 - val_accuracy: 0.8810\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3887 - accuracy: 0.9107 - val_loss: 0.4001 - val_accuracy: 0.9048\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3881 - accuracy: 0.9345 - val_loss: 0.4109 - val_accuracy: 0.8810\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 0s 332us/step - loss: 0.3874 - accuracy: 0.9167 - val_loss: 0.3929 - val_accuracy: 0.8810\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 0s 317us/step - loss: 0.3826 - accuracy: 0.9226 - val_loss: 0.3879 - val_accuracy: 0.9048\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 0s 319us/step - loss: 0.3919 - accuracy: 0.9107 - val_loss: 0.3806 - val_accuracy: 0.8810\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 0s 370us/step - loss: 0.3805 - accuracy: 0.9226 - val_loss: 0.4181 - val_accuracy: 0.9286\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 0s 277us/step - loss: 0.3843 - accuracy: 0.9286 - val_loss: 0.3859 - val_accuracy: 0.8810\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3925 - accuracy: 0.9048 - val_loss: 0.3796 - val_accuracy: 0.9048\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.4001 - accuracy: 0.8571 - val_loss: 0.3765 - val_accuracy: 0.8810\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3972 - accuracy: 0.8810 - val_loss: 0.3823 - val_accuracy: 0.8810\n",
      "Epoch 273/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.4020 - accuracy: 0.8631 - val_loss: 0.3810 - val_accuracy: 0.8810\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3809 - accuracy: 0.9107 - val_loss: 0.3752 - val_accuracy: 0.8810\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3610 - accuracy: 0.9167 - val_loss: 0.3965 - val_accuracy: 0.9286\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 0s 393us/step - loss: 0.3728 - accuracy: 0.8988 - val_loss: 0.3763 - val_accuracy: 0.8810\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3726 - accuracy: 0.9226 - val_loss: 0.4004 - val_accuracy: 0.8810\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 0s 211us/step - loss: 0.3675 - accuracy: 0.9167 - val_loss: 0.3602 - val_accuracy: 0.9048\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3635 - accuracy: 0.8988 - val_loss: 0.3639 - val_accuracy: 0.8810\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3622 - accuracy: 0.9286 - val_loss: 0.3845 - val_accuracy: 0.8810\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3520 - accuracy: 0.9167 - val_loss: 0.3622 - val_accuracy: 0.9048\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3543 - accuracy: 0.9226 - val_loss: 0.3678 - val_accuracy: 0.8810\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 0s 385us/step - loss: 0.3513 - accuracy: 0.9107 - val_loss: 0.3692 - val_accuracy: 0.8810\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 0s 250us/step - loss: 0.3534 - accuracy: 0.9286 - val_loss: 0.3519 - val_accuracy: 0.8571\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 0s 247us/step - loss: 0.3526 - accuracy: 0.9048 - val_loss: 0.3708 - val_accuracy: 0.8810\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3529 - accuracy: 0.9167 - val_loss: 0.3732 - val_accuracy: 0.8810\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3578 - accuracy: 0.9107 - val_loss: 0.3543 - val_accuracy: 0.9048\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3456 - accuracy: 0.9286 - val_loss: 0.3896 - val_accuracy: 0.9048\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3431 - accuracy: 0.9345 - val_loss: 0.3507 - val_accuracy: 0.8810\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3410 - accuracy: 0.9107 - val_loss: 0.3438 - val_accuracy: 0.9048\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3379 - accuracy: 0.9345 - val_loss: 0.3743 - val_accuracy: 0.8810\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3405 - accuracy: 0.9226 - val_loss: 0.3496 - val_accuracy: 0.8810\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3286 - accuracy: 0.9286 - val_loss: 0.3499 - val_accuracy: 0.8810\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 0s 294us/step - loss: 0.3509 - accuracy: 0.8988 - val_loss: 0.3385 - val_accuracy: 0.9048\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.3287 - accuracy: 0.9345 - val_loss: 0.3672 - val_accuracy: 0.8810\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 0s 310us/step - loss: 0.3329 - accuracy: 0.9226 - val_loss: 0.3421 - val_accuracy: 0.9048\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3331 - accuracy: 0.9345 - val_loss: 0.3297 - val_accuracy: 0.9048\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3244 - accuracy: 0.9345 - val_loss: 0.3496 - val_accuracy: 0.8810\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3421 - accuracy: 0.9286 - val_loss: 0.3728 - val_accuracy: 0.9286\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.3474 - accuracy: 0.9048 - val_loss: 0.3293 - val_accuracy: 0.9048\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 0s 370us/step - loss: 0.3192 - accuracy: 0.9345 - val_loss: 0.3465 - val_accuracy: 0.8810\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.3196 - accuracy: 0.9345 - val_loss: 0.3629 - val_accuracy: 0.9048\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 0s 304us/step - loss: 0.3191 - accuracy: 0.9286 - val_loss: 0.3284 - val_accuracy: 0.9048\n",
      "Epoch 304/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3175 - accuracy: 0.9226 - val_loss: 0.3236 - val_accuracy: 0.9048\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3067 - accuracy: 0.9286 - val_loss: 0.3414 - val_accuracy: 0.8810\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3056 - accuracy: 0.9524 - val_loss: 0.3255 - val_accuracy: 0.9048\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3070 - accuracy: 0.9405 - val_loss: 0.3231 - val_accuracy: 0.9048\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3086 - accuracy: 0.9405 - val_loss: 0.3347 - val_accuracy: 0.8810\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 0s 558us/step - loss: 0.3199 - accuracy: 0.9167 - val_loss: 0.3148 - val_accuracy: 0.9048\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.93 - 0s 279us/step - loss: 0.3050 - accuracy: 0.9286 - val_loss: 0.3330 - val_accuracy: 0.9048\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 0s 401us/step - loss: 0.3061 - accuracy: 0.9405 - val_loss: 0.3224 - val_accuracy: 0.8810\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3001 - accuracy: 0.9464 - val_loss: 0.3151 - val_accuracy: 0.9048\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2961 - accuracy: 0.9464 - val_loss: 0.3293 - val_accuracy: 0.8810\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.3051 - accuracy: 0.9226 - val_loss: 0.3272 - val_accuracy: 0.9286\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2971 - accuracy: 0.9524 - val_loss: 0.3080 - val_accuracy: 0.9048\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2944 - accuracy: 0.9524 - val_loss: 0.3249 - val_accuracy: 0.8810\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2994 - accuracy: 0.9286 - val_loss: 0.3311 - val_accuracy: 0.9286\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 0s 236us/step - loss: 0.2925 - accuracy: 0.9464 - val_loss: 0.3121 - val_accuracy: 0.9048\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 0s 217us/step - loss: 0.3017 - accuracy: 0.9107 - val_loss: 0.3010 - val_accuracy: 0.9048\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2876 - accuracy: 0.9405 - val_loss: 0.3354 - val_accuracy: 0.9286\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2949 - accuracy: 0.9345 - val_loss: 0.3258 - val_accuracy: 0.9048\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2854 - accuracy: 0.9583 - val_loss: 0.2986 - val_accuracy: 0.9048\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2879 - accuracy: 0.9286 - val_loss: 0.3172 - val_accuracy: 0.9048\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2838 - accuracy: 0.9345 - val_loss: 0.3193 - val_accuracy: 0.9048\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2742 - accuracy: 0.9583 - val_loss: 0.2951 - val_accuracy: 0.9048\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2787 - accuracy: 0.9464 - val_loss: 0.3008 - val_accuracy: 0.9048\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2743 - accuracy: 0.9583 - val_loss: 0.3200 - val_accuracy: 0.9048\n",
      "Epoch 328/1000\n",
      "168/168 [==============================] - 0s 369us/step - loss: 0.2779 - accuracy: 0.9405 - val_loss: 0.3093 - val_accuracy: 0.9048\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 0s 247us/step - loss: 0.2798 - accuracy: 0.9405 - val_loss: 0.2978 - val_accuracy: 0.8810\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 0s 316us/step - loss: 0.3139 - accuracy: 0.9167 - val_loss: 0.3123 - val_accuracy: 0.9286\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2943 - accuracy: 0.9345 - val_loss: 0.3278 - val_accuracy: 0.8810\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2882 - accuracy: 0.9226 - val_loss: 0.2979 - val_accuracy: 0.9048\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2718 - accuracy: 0.9405 - val_loss: 0.2964 - val_accuracy: 0.8810\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2718 - accuracy: 0.9405 - val_loss: 0.2966 - val_accuracy: 0.9286\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 0s 375us/step - loss: 0.2816 - accuracy: 0.9405 - val_loss: 0.3055 - val_accuracy: 0.8810\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.2735 - accuracy: 0.9464 - val_loss: 0.3068 - val_accuracy: 0.9286\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 0s 298us/step - loss: 0.2635 - accuracy: 0.9524 - val_loss: 0.3040 - val_accuracy: 0.8810\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 0s 256us/step - loss: 0.2835 - accuracy: 0.9286 - val_loss: 0.3092 - val_accuracy: 0.9286\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 0s 286us/step - loss: 0.2704 - accuracy: 0.9405 - val_loss: 0.2817 - val_accuracy: 0.9048\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2618 - accuracy: 0.9345 - val_loss: 0.2816 - val_accuracy: 0.9048\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2535 - accuracy: 0.9583 - val_loss: 0.3229 - val_accuracy: 0.8810\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2604 - accuracy: 0.9405 - val_loss: 0.2791 - val_accuracy: 0.9048\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2552 - accuracy: 0.9524 - val_loss: 0.2895 - val_accuracy: 0.9286\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2805 - accuracy: 0.9286 - val_loss: 0.3084 - val_accuracy: 0.8810\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2494 - accuracy: 0.9464 - val_loss: 0.2758 - val_accuracy: 0.9048\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 0s 341us/step - loss: 0.2751 - accuracy: 0.9167 - val_loss: 0.2674 - val_accuracy: 0.9048\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 0s 234us/step - loss: 0.2442 - accuracy: 0.9464 - val_loss: 0.3075 - val_accuracy: 0.9048\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 0s 223us/step - loss: 0.2533 - accuracy: 0.9405 - val_loss: 0.2968 - val_accuracy: 0.9286\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2945 - accuracy: 0.9048 - val_loss: 0.2789 - val_accuracy: 0.8810\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3327 - accuracy: 0.8869 - val_loss: 0.3439 - val_accuracy: 0.9048\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.3561 - accuracy: 0.8571 - val_loss: 0.2895 - val_accuracy: 0.9048\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2981 - accuracy: 0.8929 - val_loss: 0.2668 - val_accuracy: 0.9048\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 0s 366us/step - loss: 0.2582 - accuracy: 0.9464 - val_loss: 0.2817 - val_accuracy: 0.9048\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 0s 309us/step - loss: 0.2429 - accuracy: 0.9583 - val_loss: 0.2752 - val_accuracy: 0.9048\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 0s 292us/step - loss: 0.2399 - accuracy: 0.9524 - val_loss: 0.2675 - val_accuracy: 0.9048\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 0s 250us/step - loss: 0.2433 - accuracy: 0.9464 - val_loss: 0.2576 - val_accuracy: 0.9048\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 0s 250us/step - loss: 0.2462 - accuracy: 0.9464 - val_loss: 0.2809 - val_accuracy: 0.9286\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2549 - accuracy: 0.9405 - val_loss: 0.2681 - val_accuracy: 0.9048\n",
      "Epoch 359/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2334 - accuracy: 0.9583 - val_loss: 0.2726 - val_accuracy: 0.9048\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2352 - accuracy: 0.9583 - val_loss: 0.2650 - val_accuracy: 0.9048\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.2333 - accuracy: 0.9643 - val_loss: 0.2702 - val_accuracy: 0.9048\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2534 - accuracy: 0.9405 - val_loss: 0.2641 - val_accuracy: 0.9048\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 0s 397us/step - loss: 0.2490 - accuracy: 0.9286 - val_loss: 0.3264 - val_accuracy: 0.8810\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 0s 193us/step - loss: 0.2622 - accuracy: 0.9405 - val_loss: 0.2526 - val_accuracy: 0.9048\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 0s 213us/step - loss: 0.2525 - accuracy: 0.9286 - val_loss: 0.2516 - val_accuracy: 0.9048\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2403 - accuracy: 0.9464 - val_loss: 0.2898 - val_accuracy: 0.9048\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2331 - accuracy: 0.9583 - val_loss: 0.2654 - val_accuracy: 0.9048\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2441 - accuracy: 0.9464 - val_loss: 0.2474 - val_accuracy: 0.9048\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.2268 - accuracy: 0.9524 - val_loss: 0.2954 - val_accuracy: 0.9048\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 0s 301us/step - loss: 0.2355 - accuracy: 0.9405 - val_loss: 0.2675 - val_accuracy: 0.9048\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 0s 250us/step - loss: 0.2208 - accuracy: 0.9643 - val_loss: 0.2610 - val_accuracy: 0.9048\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.2226 - accuracy: 0.9583 - val_loss: 0.2580 - val_accuracy: 0.9048\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 0s 298us/step - loss: 0.2193 - accuracy: 0.9583 - val_loss: 0.2834 - val_accuracy: 0.9286\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 0s 256us/step - loss: 0.2369 - accuracy: 0.9345 - val_loss: 0.2552 - val_accuracy: 0.9048\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 0s 262us/step - loss: 0.2308 - accuracy: 0.9464 - val_loss: 0.2600 - val_accuracy: 0.9286\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 0s 272us/step - loss: 0.2510 - accuracy: 0.9345 - val_loss: 0.2558 - val_accuracy: 0.9048\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.2270 - accuracy: 0.9524 - val_loss: 0.2666 - val_accuracy: 0.9048\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.2164 - accuracy: 0.9643 - val_loss: 0.2574 - val_accuracy: 0.9048\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 0s 280us/step - loss: 0.2217 - accuracy: 0.9524 - val_loss: 0.2496 - val_accuracy: 0.9048\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 0s 250us/step - loss: 0.2469 - accuracy: 0.9464 - val_loss: 0.3257 - val_accuracy: 0.9048\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 0s 321us/step - loss: 0.2292 - accuracy: 0.9464 - val_loss: 0.2377 - val_accuracy: 0.9048\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 0s 246us/step - loss: 0.2253 - accuracy: 0.9405 - val_loss: 0.2362 - val_accuracy: 0.9048\n",
      "Epoch 383/1000\n",
      "168/168 [==============================] - 0s 225us/step - loss: 0.2173 - accuracy: 0.9524 - val_loss: 0.2686 - val_accuracy: 0.9286\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2202 - accuracy: 0.9524 - val_loss: 0.2732 - val_accuracy: 0.9286\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2200 - accuracy: 0.9583 - val_loss: 0.2370 - val_accuracy: 0.9048\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.96 - 0s 186us/step - loss: 0.2155 - accuracy: 0.9702 - val_loss: 0.2576 - val_accuracy: 0.9048\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2078 - accuracy: 0.9643 - val_loss: 0.2398 - val_accuracy: 0.9286\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2142 - accuracy: 0.9583 - val_loss: 0.2491 - val_accuracy: 0.9048\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 0s 339us/step - loss: 0.2169 - accuracy: 0.9583 - val_loss: 0.2601 - val_accuracy: 0.9286\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2149 - accuracy: 0.9583 - val_loss: 0.2335 - val_accuracy: 0.9286\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2109 - accuracy: 0.9524 - val_loss: 0.2559 - val_accuracy: 0.9048\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2133 - accuracy: 0.9643 - val_loss: 0.2618 - val_accuracy: 0.9048\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.2092 - accuracy: 0.9643 - val_loss: 0.2339 - val_accuracy: 0.9286\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2204 - accuracy: 0.9464 - val_loss: 0.2445 - val_accuracy: 0.9524\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.93 - 0s 186us/step - loss: 0.2216 - accuracy: 0.9286 - val_loss: 0.2625 - val_accuracy: 0.9286\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 0s 293us/step - loss: 0.2156 - accuracy: 0.9464 - val_loss: 0.2345 - val_accuracy: 0.9286\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2150 - accuracy: 0.9524 - val_loss: 0.2260 - val_accuracy: 0.9048\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 0s 378us/step - loss: 0.2008 - accuracy: 0.9583 - val_loss: 0.2725 - val_accuracy: 0.9524\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2200 - accuracy: 0.9345 - val_loss: 0.2572 - val_accuracy: 0.9524\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1985 - accuracy: 0.9583 - val_loss: 0.2236 - val_accuracy: 0.9048\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2145 - accuracy: 0.9464 - val_loss: 0.2294 - val_accuracy: 0.9286\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.2030 - accuracy: 0.9524 - val_loss: 0.2561 - val_accuracy: 0.9286\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2009 - accuracy: 0.9702 - val_loss: 0.2327 - val_accuracy: 0.9286\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2041 - accuracy: 0.9464 - val_loss: 0.2293 - val_accuracy: 0.9286\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 0s 370us/step - loss: 0.2070 - accuracy: 0.9405 - val_loss: 0.2399 - val_accuracy: 0.9286\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 0s 297us/step - loss: 0.2123 - accuracy: 0.9524 - val_loss: 0.2554 - val_accuracy: 0.9286\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 0s 259us/step - loss: 0.1981 - accuracy: 0.9583 - val_loss: 0.2280 - val_accuracy: 0.9286\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2120 - accuracy: 0.9405 - val_loss: 0.2239 - val_accuracy: 0.9286\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2108 - accuracy: 0.9583 - val_loss: 0.2320 - val_accuracy: 0.9286\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1922 - accuracy: 0.9702 - val_loss: 0.2402 - val_accuracy: 0.9286\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1899 - accuracy: 0.9702 - val_loss: 0.2399 - val_accuracy: 0.9286\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1935 - accuracy: 0.9702 - val_loss: 0.2340 - val_accuracy: 0.9286\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.2010 - accuracy: 0.9524 - val_loss: 0.2396 - val_accuracy: 0.9286\n",
      "Epoch 414/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.1911 - accuracy: 0.9643 - val_loss: 0.2284 - val_accuracy: 0.9286\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 0s 356us/step - loss: 0.1900 - accuracy: 0.9583 - val_loss: 0.2299 - val_accuracy: 0.9286\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 0s 258us/step - loss: 0.1950 - accuracy: 0.9702 - val_loss: 0.2560 - val_accuracy: 0.9286\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 0s 221us/step - loss: 0.2009 - accuracy: 0.9524 - val_loss: 0.2322 - val_accuracy: 0.9286\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1969 - accuracy: 0.9643 - val_loss: 0.2228 - val_accuracy: 0.9286\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1862 - accuracy: 0.9583 - val_loss: 0.2311 - val_accuracy: 0.9286\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1882 - accuracy: 0.9583 - val_loss: 0.2303 - val_accuracy: 0.9286\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1838 - accuracy: 0.9702 - val_loss: 0.2192 - val_accuracy: 0.9524\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 0s 309us/step - loss: 0.1852 - accuracy: 0.9583 - val_loss: 0.2296 - val_accuracy: 0.9524\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 0s 263us/step - loss: 0.1891 - accuracy: 0.9643 - val_loss: 0.2659 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.1974 - accuracy: 0.9464 - val_loss: 0.2285 - val_accuracy: 0.9286\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 0s 213us/step - loss: 0.1878 - accuracy: 0.9643 - val_loss: 0.2174 - val_accuracy: 0.9524\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1925 - accuracy: 0.9405 - val_loss: 0.2325 - val_accuracy: 0.9286\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1912 - accuracy: 0.9643 - val_loss: 0.2480 - val_accuracy: 0.9524\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1862 - accuracy: 0.9524 - val_loss: 0.2123 - val_accuracy: 0.9286\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.96 - 0s 186us/step - loss: 0.1886 - accuracy: 0.9524 - val_loss: 0.2133 - val_accuracy: 0.9524\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1848 - accuracy: 0.9643 - val_loss: 0.2393 - val_accuracy: 0.9286\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1893 - accuracy: 0.9643 - val_loss: 0.2269 - val_accuracy: 0.9286\n",
      "Epoch 432/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1902 - accuracy: 0.9345 - val_loss: 0.2099 - val_accuracy: 0.9524\n",
      "Epoch 433/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1825 - accuracy: 0.9762 - val_loss: 0.2403 - val_accuracy: 0.9524\n",
      "Epoch 434/1000\n",
      "168/168 [==============================] - 0s 328us/step - loss: 0.1808 - accuracy: 0.9643 - val_loss: 0.2221 - val_accuracy: 0.9286\n",
      "Epoch 435/1000\n",
      "168/168 [==============================] - 0s 312us/step - loss: 0.1765 - accuracy: 0.9643 - val_loss: 0.2211 - val_accuracy: 0.9524\n",
      "Epoch 436/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1805 - accuracy: 0.9643 - val_loss: 0.2312 - val_accuracy: 0.9524\n",
      "Epoch 437/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1767 - accuracy: 0.9702 - val_loss: 0.2081 - val_accuracy: 0.9524\n",
      "Epoch 438/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1878 - accuracy: 0.9464 - val_loss: 0.2166 - val_accuracy: 0.9524\n",
      "Epoch 439/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1914 - accuracy: 0.9583 - val_loss: 0.2855 - val_accuracy: 0.9286\n",
      "Epoch 440/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1946 - accuracy: 0.9405 - val_loss: 0.2106 - val_accuracy: 0.9286\n",
      "Epoch 441/1000\n",
      "168/168 [==============================] - 0s 589us/step - loss: 0.1851 - accuracy: 0.9643 - val_loss: 0.2193 - val_accuracy: 0.9524\n",
      "Epoch 442/1000\n",
      "168/168 [==============================] - 0s 313us/step - loss: 0.1807 - accuracy: 0.9643 - val_loss: 0.2523 - val_accuracy: 0.9524\n",
      "Epoch 443/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1762 - accuracy: 0.9583 - val_loss: 0.2046 - val_accuracy: 0.9524\n",
      "Epoch 444/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1760 - accuracy: 0.9583 - val_loss: 0.2068 - val_accuracy: 0.9286\n",
      "Epoch 445/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1718 - accuracy: 0.9702 - val_loss: 0.2281 - val_accuracy: 0.9286\n",
      "Epoch 446/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1730 - accuracy: 0.9583 - val_loss: 0.2176 - val_accuracy: 0.9286\n",
      "Epoch 447/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1727 - accuracy: 0.9643 - val_loss: 0.2195 - val_accuracy: 0.9524\n",
      "Epoch 448/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1667 - accuracy: 0.9643 - val_loss: 0.2072 - val_accuracy: 0.9524\n",
      "Epoch 449/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1736 - accuracy: 0.9643 - val_loss: 0.2087 - val_accuracy: 0.9524\n",
      "Epoch 450/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1718 - accuracy: 0.9643 - val_loss: 0.2142 - val_accuracy: 0.9524\n",
      "Epoch 451/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1745 - accuracy: 0.9583 - val_loss: 0.2090 - val_accuracy: 0.9524\n",
      "Epoch 452/1000\n",
      "168/168 [==============================] - 0s 272us/step - loss: 0.1671 - accuracy: 0.9643 - val_loss: 0.2102 - val_accuracy: 0.9524\n",
      "Epoch 453/1000\n",
      "168/168 [==============================] - 0s 223us/step - loss: 0.1659 - accuracy: 0.9702 - val_loss: 0.2174 - val_accuracy: 0.9524\n",
      "Epoch 454/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1677 - accuracy: 0.9702 - val_loss: 0.2118 - val_accuracy: 0.9286\n",
      "Epoch 455/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1672 - accuracy: 0.9762 - val_loss: 0.2098 - val_accuracy: 0.9524\n",
      "Epoch 456/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1656 - accuracy: 0.9702 - val_loss: 0.2074 - val_accuracy: 0.9524\n",
      "Epoch 457/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1646 - accuracy: 0.9643 - val_loss: 0.2106 - val_accuracy: 0.9286\n",
      "Epoch 458/1000\n",
      "168/168 [==============================] - 0s 366us/step - loss: 0.1760 - accuracy: 0.9524 - val_loss: 0.2085 - val_accuracy: 0.9524\n",
      "Epoch 459/1000\n",
      "168/168 [==============================] - 0s 321us/step - loss: 0.1732 - accuracy: 0.9702 - val_loss: 0.2058 - val_accuracy: 0.9524\n",
      "Epoch 460/1000\n",
      "168/168 [==============================] - 0s 256us/step - loss: 0.1678 - accuracy: 0.9643 - val_loss: 0.2047 - val_accuracy: 0.9524\n",
      "Epoch 461/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1638 - accuracy: 0.9702 - val_loss: 0.2110 - val_accuracy: 0.9286\n",
      "Epoch 462/1000\n",
      "168/168 [==============================] - 0s 291us/step - loss: 0.1914 - accuracy: 0.9524 - val_loss: 0.2106 - val_accuracy: 0.9524\n",
      "Epoch 463/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1710 - accuracy: 0.9643 - val_loss: 0.2078 - val_accuracy: 0.9286\n",
      "Epoch 464/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1723 - accuracy: 0.9405 - val_loss: 0.1973 - val_accuracy: 0.9524\n",
      "Epoch 465/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1613 - accuracy: 0.9702 - val_loss: 0.2333 - val_accuracy: 0.9524\n",
      "Epoch 466/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1637 - accuracy: 0.9583 - val_loss: 0.2021 - val_accuracy: 0.9762\n",
      "Epoch 467/1000\n",
      "168/168 [==============================] - 0s 558us/step - loss: 0.1655 - accuracy: 0.9583 - val_loss: 0.1951 - val_accuracy: 0.9286\n",
      "Epoch 468/1000\n",
      "168/168 [==============================] - 0s 288us/step - loss: 0.1725 - accuracy: 0.9643 - val_loss: 0.2295 - val_accuracy: 0.9524\n",
      "Epoch 469/1000\n",
      "168/168 [==============================] - 0s 254us/step - loss: 0.1674 - accuracy: 0.9524 - val_loss: 0.2061 - val_accuracy: 0.9762\n",
      "Epoch 470/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1623 - accuracy: 0.9643 - val_loss: 0.2062 - val_accuracy: 0.9524\n",
      "Epoch 471/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1593 - accuracy: 0.9702 - val_loss: 0.2193 - val_accuracy: 0.9524\n",
      "Epoch 472/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1602 - accuracy: 0.9643 - val_loss: 0.1962 - val_accuracy: 0.9524\n",
      "Epoch 473/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1657 - accuracy: 0.9643 - val_loss: 0.1956 - val_accuracy: 0.9524\n",
      "Epoch 474/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1571 - accuracy: 0.9762 - val_loss: 0.2208 - val_accuracy: 0.9524\n",
      "Epoch 475/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1612 - accuracy: 0.9583 - val_loss: 0.2065 - val_accuracy: 0.9762\n",
      "Epoch 476/1000\n",
      "168/168 [==============================] - 0s 349us/step - loss: 0.1577 - accuracy: 0.9762 - val_loss: 0.1973 - val_accuracy: 0.9524\n",
      "Epoch 477/1000\n",
      "168/168 [==============================] - 0s 311us/step - loss: 0.1600 - accuracy: 0.9643 - val_loss: 0.2101 - val_accuracy: 0.9286\n",
      "Epoch 478/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1731 - accuracy: 0.9583 - val_loss: 0.2080 - val_accuracy: 0.9524\n",
      "Epoch 479/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.1805 - accuracy: 0.9524 - val_loss: 0.2064 - val_accuracy: 0.9286\n",
      "Epoch 480/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1891 - accuracy: 0.9464 - val_loss: 0.2101 - val_accuracy: 0.9524\n",
      "Epoch 481/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1963 - accuracy: 0.9286 - val_loss: 0.1899 - val_accuracy: 0.9286\n",
      "Epoch 482/1000\n",
      "168/168 [==============================] - 0s 294us/step - loss: 0.1703 - accuracy: 0.9583 - val_loss: 0.2544 - val_accuracy: 0.9286\n",
      "Epoch 483/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1759 - accuracy: 0.9524 - val_loss: 0.2107 - val_accuracy: 0.9762\n",
      "Epoch 484/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1600 - accuracy: 0.9583 - val_loss: 0.1870 - val_accuracy: 0.9286\n",
      "Epoch 485/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1589 - accuracy: 0.9702 - val_loss: 0.2305 - val_accuracy: 0.9524\n",
      "Epoch 486/1000\n",
      "168/168 [==============================] - 0s 373us/step - loss: 0.1602 - accuracy: 0.9524 - val_loss: 0.1965 - val_accuracy: 0.9524\n",
      "Epoch 487/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1548 - accuracy: 0.9702 - val_loss: 0.1989 - val_accuracy: 0.9762\n",
      "Epoch 488/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1552 - accuracy: 0.9762 - val_loss: 0.2059 - val_accuracy: 0.9524\n",
      "Epoch 489/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1547 - accuracy: 0.9702 - val_loss: 0.2056 - val_accuracy: 0.9762\n",
      "Epoch 490/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1638 - accuracy: 0.9583 - val_loss: 0.1986 - val_accuracy: 0.9524\n",
      "Epoch 491/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1527 - accuracy: 0.9643 - val_loss: 0.1967 - val_accuracy: 0.9762\n",
      "Epoch 492/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1528 - accuracy: 0.9702 - val_loss: 0.1922 - val_accuracy: 0.9524\n",
      "Epoch 493/1000\n",
      "168/168 [==============================] - 0s 742us/step - loss: 0.1543 - accuracy: 0.9702 - val_loss: 0.1964 - val_accuracy: 0.9762\n",
      "Epoch 494/1000\n",
      "168/168 [==============================] - 0s 274us/step - loss: 0.1507 - accuracy: 0.9702 - val_loss: 0.2076 - val_accuracy: 0.9524\n",
      "Epoch 495/1000\n",
      "168/168 [==============================] - 0s 285us/step - loss: 0.1566 - accuracy: 0.9762 - val_loss: 0.2006 - val_accuracy: 0.9524\n",
      "Epoch 496/1000\n",
      "168/168 [==============================] - 0s 268us/step - loss: 0.1810 - accuracy: 0.9464 - val_loss: 0.1863 - val_accuracy: 0.9524\n",
      "Epoch 497/1000\n",
      "168/168 [==============================] - 0s 256us/step - loss: 0.1517 - accuracy: 0.9643 - val_loss: 0.2311 - val_accuracy: 0.9286\n",
      "Epoch 498/1000\n",
      "168/168 [==============================] - 0s 262us/step - loss: 0.1571 - accuracy: 0.9524 - val_loss: 0.2021 - val_accuracy: 0.9524\n",
      "Epoch 499/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1513 - accuracy: 0.9702 - val_loss: 0.1822 - val_accuracy: 0.9524\n",
      "Epoch 500/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1532 - accuracy: 0.9643 - val_loss: 0.2036 - val_accuracy: 0.9524\n",
      "Epoch 501/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1505 - accuracy: 0.9643 - val_loss: 0.1945 - val_accuracy: 0.9762\n",
      "Epoch 502/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1481 - accuracy: 0.9702 - val_loss: 0.1838 - val_accuracy: 0.9524\n",
      "Epoch 503/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1480 - accuracy: 0.9702 - val_loss: 0.2053 - val_accuracy: 0.9524\n",
      "Epoch 504/1000\n",
      "168/168 [==============================] - 0s 336us/step - loss: 0.1486 - accuracy: 0.9643 - val_loss: 0.1956 - val_accuracy: 0.9762\n",
      "Epoch 505/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1496 - accuracy: 0.9762 - val_loss: 0.1977 - val_accuracy: 0.9524\n",
      "Epoch 506/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1538 - accuracy: 0.9643 - val_loss: 0.2159 - val_accuracy: 0.9524\n",
      "Epoch 507/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1528 - accuracy: 0.9583 - val_loss: 0.1832 - val_accuracy: 0.9524\n",
      "Epoch 508/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1499 - accuracy: 0.9643 - val_loss: 0.1956 - val_accuracy: 0.9762\n",
      "Epoch 509/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1624 - accuracy: 0.9464 - val_loss: 0.1974 - val_accuracy: 0.9524\n",
      "Epoch 510/1000\n",
      "168/168 [==============================] - 0s 299us/step - loss: 0.1856 - accuracy: 0.9286 - val_loss: 0.1866 - val_accuracy: 0.9524\n",
      "Epoch 511/1000\n",
      "168/168 [==============================] - 0s 299us/step - loss: 0.2035 - accuracy: 0.9286 - val_loss: 0.2037 - val_accuracy: 0.9524\n",
      "Epoch 512/1000\n",
      "168/168 [==============================] - 0s 306us/step - loss: 0.1500 - accuracy: 0.9583 - val_loss: 0.1927 - val_accuracy: 0.9524\n",
      "Epoch 513/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1437 - accuracy: 0.9643 - val_loss: 0.1980 - val_accuracy: 0.9762\n",
      "Epoch 514/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1464 - accuracy: 0.9643 - val_loss: 0.1863 - val_accuracy: 0.9524\n",
      "Epoch 515/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1449 - accuracy: 0.9762 - val_loss: 0.2046 - val_accuracy: 0.9524\n",
      "Epoch 516/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1548 - accuracy: 0.9583 - val_loss: 0.2193 - val_accuracy: 0.9524\n",
      "Epoch 517/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1479 - accuracy: 0.9702 - val_loss: 0.1751 - val_accuracy: 0.9286\n",
      "Epoch 518/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1546 - accuracy: 0.9583 - val_loss: 0.1928 - val_accuracy: 0.9524\n",
      "Epoch 519/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1447 - accuracy: 0.9702 - val_loss: 0.2009 - val_accuracy: 0.9524\n",
      "Epoch 520/1000\n",
      "168/168 [==============================] - 0s 465us/step - loss: 0.1411 - accuracy: 0.9821 - val_loss: 0.1866 - val_accuracy: 0.9762\n",
      "Epoch 521/1000\n",
      "168/168 [==============================] - 0s 366us/step - loss: 0.1687 - accuracy: 0.9643 - val_loss: 0.1918 - val_accuracy: 0.9524\n",
      "Epoch 522/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1922 - accuracy: 0.9345 - val_loss: 0.2221 - val_accuracy: 0.9286\n",
      "Epoch 523/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1695 - accuracy: 0.9524 - val_loss: 0.1762 - val_accuracy: 0.9286\n",
      "Epoch 524/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1530 - accuracy: 0.9583 - val_loss: 0.2319 - val_accuracy: 0.9286\n",
      "Epoch 525/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1566 - accuracy: 0.9524 - val_loss: 0.2156 - val_accuracy: 0.9524\n",
      "Epoch 526/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1492 - accuracy: 0.9583 - val_loss: 0.1752 - val_accuracy: 0.9762\n",
      "Epoch 527/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1497 - accuracy: 0.9643 - val_loss: 0.1958 - val_accuracy: 0.9524\n",
      "Epoch 528/1000\n",
      "168/168 [==============================] - 0s 302us/step - loss: 0.1465 - accuracy: 0.9762 - val_loss: 0.1973 - val_accuracy: 0.9762\n",
      "Epoch 529/1000\n",
      "168/168 [==============================] - 0s 250us/step - loss: 0.1473 - accuracy: 0.9643 - val_loss: 0.1800 - val_accuracy: 0.9524\n",
      "Epoch 530/1000\n",
      "168/168 [==============================] - 0s 173us/step - loss: 0.1404 - accuracy: 0.9762 - val_loss: 0.1887 - val_accuracy: 0.9762\n",
      "Epoch 531/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1418 - accuracy: 0.9762 - val_loss: 0.1837 - val_accuracy: 0.9524\n",
      "Epoch 532/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1410 - accuracy: 0.9702 - val_loss: 0.1830 - val_accuracy: 0.9762\n",
      "Epoch 533/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1496 - accuracy: 0.9524 - val_loss: 0.2063 - val_accuracy: 0.9524\n",
      "Epoch 534/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 279us/step - loss: 0.1448 - accuracy: 0.9643 - val_loss: 0.1783 - val_accuracy: 0.9524\n",
      "Epoch 535/1000\n",
      "168/168 [==============================] - 0s 186us/step - loss: 0.1367 - accuracy: 0.9762 - val_loss: 0.1906 - val_accuracy: 0.9762\n",
      "Epoch 536/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1383 - accuracy: 0.9702 - val_loss: 0.1784 - val_accuracy: 0.9762\n",
      "Epoch 537/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1416 - accuracy: 0.9702 - val_loss: 0.1762 - val_accuracy: 0.9762\n",
      "Epoch 538/1000\n",
      "168/168 [==============================] - 0s 372us/step - loss: 0.1365 - accuracy: 0.9702 - val_loss: 0.1945 - val_accuracy: 0.9762\n",
      "Epoch 539/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1371 - accuracy: 0.9702 - val_loss: 0.1901 - val_accuracy: 0.9762\n",
      "Epoch 540/1000\n",
      "168/168 [==============================] - 0s 311us/step - loss: 0.1373 - accuracy: 0.9583 - val_loss: 0.1853 - val_accuracy: 0.9762\n",
      "Epoch 541/1000\n",
      "168/168 [==============================] - 0s 222us/step - loss: 0.1366 - accuracy: 0.9643 - val_loss: 0.1900 - val_accuracy: 0.9524\n",
      "Epoch 542/1000\n",
      "168/168 [==============================] - 0s 279us/step - loss: 0.1437 - accuracy: 0.9702 - val_loss: 0.1764 - val_accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "# Fit the models to the training data\n",
    "nn_fit = nn.fit(X_train, y_train, epochs=num_epochs, validation_split=.3, callbacks=[early_stopping_monitor], \n",
    "                validation_data=(X_test, y_test), verbose=1)\n",
    "nn2_fit = nn2.fit(X2_train, y2_train, epochs=num_epochs, validation_split=.3, callbacks=[early_stopping_monitor], \n",
    "                validation_data=(X2_test, y2_test), verbose=1)\n",
    "nn3_fit = nn3.fit(X3_train, y3_train, epochs=num_epochs, validation_split=.3, callbacks=[early_stopping_monitor], \n",
    "                validation_data=(X3_test, y3_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 372us/step\n",
      "42/42 [==============================] - 0s 372us/step\n",
      "42/42 [==============================] - 0s 372us/step\n"
     ]
    }
   ],
   "source": [
    "# Score the models' performance\n",
    "score = nn.evaluate(X_test, y_test)\n",
    "score2 = nn2.evaluate(X2_test, y2_test)\n",
    "score3 = nn3.evaluate(X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.2591    Test accuracy: 85.71 %\n",
      "\n",
      "Test2 loss: 0.2348    Test2 accuracy: 88.1 %\n",
      "\n",
      "Test3 loss: 0.1764    Test3 accuracy: 97.61999999999999 %\n"
     ]
    }
   ],
   "source": [
    "# Get the scores\n",
    "loss, accuracy = score\n",
    "loss2, accuracy2 = score2\n",
    "loss3, accuracy3 = score3\n",
    "\n",
    "print('\\nTest loss:', round(loss,4), '   Test accuracy:', round(accuracy,4)*100,'%')\n",
    "print('\\nTest2 loss:', round(loss2,4), '   Test2 accuracy:', round(accuracy2,4)*100,'%')\n",
    "print('\\nTest3 loss:', round(loss3,4), '   Test3 accuracy:', round(accuracy3,4)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create plots\n",
    "_=plt.figure(figsize=(14,7))\n",
    "_=plt.subplot(3,1,1)\n",
    "_=plt.title('Neural Network 1 Performance')\n",
    "_=plt.plot(nn_fit.history['val_loss'], 'k')\n",
    "_=plt.plot(nn_fit.history['val_accuracy'])\n",
    "_=plt.ylim(loss-.2,1)\n",
    "_=plt.axhline(max(nn_fit.history['val_accuracy']), linestyle=':', linewidth=1)\n",
    "_=plt.axhline(min(nn_fit.history['val_loss']), linestyle=':', linewidth=1, c='k')\n",
    "_=plt.axhline(loss, linestyle='-.', linewidth=2, c='r')\n",
    "_=plt.axhline(accuracy, linestyle='-.', linewidth=2, c='g')\n",
    "_=plt.xlabel('Epochs')\n",
    "\n",
    "_=plt.subplot(3,1,2)\n",
    "_=plt.title('Neural Network 2 Performance')\n",
    "_=plt.plot(nn2_fit.history['val_loss'], 'k')\n",
    "_=plt.plot(nn2_fit.history['val_accuracy'])\n",
    "_=plt.ylim(loss2-.2,1)\n",
    "_=plt.axhline(max(nn2_fit.history['val_accuracy']), linestyle=':', linewidth=1)\n",
    "_=plt.axhline(min(nn2_fit.history['val_loss']), linestyle=':', linewidth=1, c='k')\n",
    "_=plt.axhline(loss2, linestyle='-.', linewidth=2, c='r')\n",
    "_=plt.axhline(accuracy2, linestyle='-.', linewidth=2, c='g')\n",
    "_=plt.xlabel('Epochs')\n",
    "_=plt.ylabel('Validation score')\n",
    "_=plt.legend(['validation loss','validation accuracy', 'accuracy max', 'loss min', 'test loss', 'test accuracy'])\n",
    "\n",
    "_=plt.subplot(3,1,3)\n",
    "_=plt.title('Neural Network 3 Performance')\n",
    "_=plt.plot(nn3_fit.history['val_loss'], 'k')\n",
    "_=plt.plot(nn3_fit.history['val_accuracy'])\n",
    "#_=plt.ylim(loss3-.2,1)\n",
    "_=plt.axhline(max(nn3_fit.history['val_accuracy']), linestyle=':', linewidth=1)\n",
    "_=plt.axhline(min(nn3_fit.history['val_loss']), linestyle=':', linewidth=1, c='k')\n",
    "_=plt.axhline(loss3, linestyle='-.', linewidth=2, c='r')\n",
    "_=plt.axhline(accuracy3, linestyle='-.', linewidth=2, c='g')\n",
    "_=plt.xlabel('Epochs')\n",
    "_=plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seeds dataset, though small, is rich in information. The logistic regression model performed best, with a neural network showing similar results using features with those highly correlated removed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
